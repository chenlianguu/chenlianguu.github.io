<!DOCTYPE html>
<html lang="zh-CN">





<head>
  <meta charset="UTF-8">
  <link rel="apple-touch-icon" sizes="76x76" href="/img/apple-touch-icon.png">
  <link rel="icon" type="image/png" href="https://i.loli.net/2020/01/09/gqn1D9aJRP3iCcm.png">
  <meta name="viewport"
        content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, shrink-to-fit=no">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  
    <meta http-equiv="Content-Security-Policy" content="upgrade-insecure-requests">
  
  <meta name="description" content="111">
  <meta name="author" content="Chen Liang">
  <meta name="keywords" content="">
  <title>Chen Space</title>

  <link rel="stylesheet" href="https://cdn.staticfile.org/font-awesome/5.10.2/css/all.min.css"  >
<link rel="stylesheet" href="https://cdn.staticfile.org/twitter-bootstrap/4.3.1/css/bootstrap.min.css"  >
<link rel="stylesheet" href="https://cdn.staticfile.org/mdbootstrap/4.8.9/css/mdb.min.css"  >
<link rel="stylesheet" href="https://cdn.staticfile.org/github-markdown-css/3.0.1/github-markdown.min.css"  >

<link rel="stylesheet" href="//at.alicdn.com/t/font_1067060_qzomjdt8bmp.css">



  <link rel="stylesheet" href="/lib/prettify/tomorrow-night-eighties.min.css"  >

<link rel="stylesheet" href="/css/main.css"  >


  <link rel="stylesheet" href="https://cdn.staticfile.org/fancybox/3.5.7/jquery.fancybox.min.css"  >


<meta name="generator" content="Hexo 4.2.0"></head>


<body>
  <header style="height: 100vh;">
    <nav id="navbar" class="navbar fixed-top  navbar-expand-lg navbar-dark scrolling-navbar">
  <div class="container">
    <a class="navbar-brand"
       href="/">&nbsp;<strong>Chen Space</strong>&nbsp;</a>

    <button id="navbar-toggler-btn" class="navbar-toggler" type="button" data-toggle="collapse"
            data-target="#navbarSupportedContent"
            aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
      <div class="animated-icon"><span></span><span></span><span></span></div>
    </button>

    <!-- Collapsible content -->
    <div class="collapse navbar-collapse" id="navbarSupportedContent">
      <ul class="navbar-nav ml-auto text-center">
        
          
          
          
          
          <li class="nav-item">
            <a class="nav-link" href="/">首页</a>
          </li>
        
          
          
          
          
          <li class="nav-item">
            <a class="nav-link" href="/archives/">归档</a>
          </li>
        
          
          
          
          
          <li class="nav-item">
            <a class="nav-link" href="/categories/">分类</a>
          </li>
        
          
          
          
          
          <li class="nav-item">
            <a class="nav-link" href="/tags/">标签</a>
          </li>
        
          
          
          
          
          <li class="nav-item">
            <a class="nav-link" href="/about/">关于</a>
          </li>
        
        
          <li class="nav-item" id="search-btn">
            <a class="nav-link" data-toggle="modal" data-target="#modalSearch">&nbsp;&nbsp;<i
                class="iconfont icon-search"></i>&nbsp;&nbsp;</a>
          </li>
        
      </ul>
    </div>
  </div>
</nav>

    <div class="view intro-2" id="background"
         style="background: url('https://i.loli.net/2020/01/09/iBerVkKW4fNmMLY.jpg')no-repeat center center;
           background-size: cover;
           background-attachment: fixed;">
      <div class="full-bg-img">
        <div class="mask rgba-black-light flex-center">
          <div class="container text-center white-text fadeInUp">
            <span class="h2" id="subtitle">
              
            </span>

            
          </div>

          
            <div class="scroll-down-bar">
              <i class="fas fa-angle-down scroll-down-arrow"></i>
            </div>
          
        </div>
      </div>
    </div>
  </header>

  <main>
    
      <div class="container nopadding-md">
        <div class="py-5 z-depth-3" id="board">
          
          <div class="container">
            <div class="row">
              <div class="col-12 col-md-10 m-auto">
                


  <div class="row mb-4 mx-auto">
    
    
      <div class="col-12 col-md-4 m-auto">
        <a href="/2020/01/09/Jenkins%E4%BD%BF%E7%94%A8%E6%8C%87%E5%8D%97/" target="_self">
          <img src="https://i.loli.net/2020/01/09/aQSYzXWHexZGBLu.png" srcset="/img/loading.gif" alt="Jenkins使用指南" class="img-fluid rounded z-depth-3 index-thumbnails">
        </a>
      </div>
    
    <div class="col-12 col-md-8 m-auto">
      <a href="/2020/01/09/Jenkins%E4%BD%BF%E7%94%A8%E6%8C%87%E5%8D%97/">
        <p class="h4 index-header">Jenkins使用指南</p>
        
        
          
        
        <div class="index-excerpt" >
          <div class="index-text mb-1">简介Jenkins是一个广泛用于持续构建的可视化web工具，持续构建说得更直白点，就是各种项目的”自动化”编译、打包、分发部署。jenkins可以很好的支持各种语言（比如：java, c#, php等）的项目构建，也完全兼容ant、maven、gradle等多种第三方构建工具，同时跟svn、git能无缝集成，也支持直接与知名源代码托管网站，比如github、bitbucket直接集成。简单点说，Jenkins其实就是大的框架集，可以整个任何你想整合的内容，实现公司的整个持续集成体系！
安装基于docker安装：
docker run -it \
  --name jenkins \
  --restart always \
  --user root \
  -p 10002:8080 \
  -p 50000:50000 \
  -v /data/jenkins_home:/var/jenkins_home \
  -v /var/run/docker.sock:/var/run/docker.sock \
  -v /opt/jdk1.8.0_25:/opt/jdk1.8.0_25 \
  -v /bin/docker:/bin/docker \
  -v /data/repository:/data/repository \
  -v $(which docker):/usr/bin/docker \
  jenkins/jenkins:lts
注意：需要使用jenkins/jenkins:lts镜像，jenkins:latest镜像官方已不提供支持，版本过低
其中将外部docker映射到了内部docker，这样在jenkins容器内部也可以使用docker命令了
注意启动之后会有个随机的密码：例：ff9c1128af2840d990798418bd3c92f2
如果采用以-it的形式启动，可以在命令窗口中看到。

当然也可以进入容器，在/var/jenkins_home/secrets/initialAdminPassword中找到。
注意！映射在容器中的/var/jenkins_home 目录到具有名字 jenkins-data 的volume。 如果这个卷不存在，那么这个 docker run 命令会自动为你创建卷。 如果您希望每次重新启动Jenkins（通过此 docker run … 命令）时保持Jenkins状态，则此选项是必需的，jenkins数据会在该卷进行持久化 。 否则，那么在每次重新启动后，Jenkins将有效地重置为新的实例。
（可选 /var/run/docker.sock 表示Docker守护程序通过其监听的基于Unix的套接字。 该映射允许 jenkinsci/blueocean 容器与Docker守护进程通信， 如果 jenkinsci/blueocean 容器需要实例化其他Docker容器，则该守护进程是必需的。 如果运行声明式管道，其语法包含agent部分用 docker.
进入 ip:10002 jenkins安装界面

安装对应插件
Demo本Demo实现的场景是push到项目master分支，自动触发打包发布到docker镜像仓库harbor，然后在拉取镜像在docker中运行项目Demo地址：http://161.189.27.8:8090/chenliang/jenkinsdemo
jenkins项目地址：http://52.83.79.244:10002/job/jenkins-demo
大家可以拉取项目Demo代码，修改代码push提交master，自动触发打包执行，在jenkins的console output查看执行信息
初始化
step1 gitlab新建项目 比如jenkins-demo

step2 
jenkins添加gitlab账户及密码
凭据—&gt;系统—&gt;全局凭据—&gt;add credentials


step3  jenkins新建项目，选择maven项目—source code managment
填写项目的地址，选择step生成的credentials，选择代码分支





step4  选择Build Trigger—&gt;勾选gitlab触发选项—&gt;点击generate生成scretkey并记住—&gt;复制gitlab webhook的url
url及secretkey在gitlab设置中需要用




step5 回到gitlab项目的setting的integration页面中，填写step4中的url及secretkey，取消勾选ssl



step6 build中填写构建maven命令及构建后需要执行的程序，本demo执行的是打包然后java命令执行jar包


测试以gitlab项目jenkinsdemo为例：http://161.189.27.8:8090/chenliang/jenkinsdemo 当修改代码push到master中的时候会自动出发打包及执行jar包，在jenkins项目的console output中查看打包及执行日志

trouble shooting安装插件报错
更改jenkins源—&gt;进入系统管理—&gt;管理插件—&gt;高级 
将
http://updates.jenkins-ci.org/update-center.json更换为
http://mirror.esuni.jp/jenkins/updates/update-center.json保存即可

jenkins内部执行docker命令报错docker内部执行docker报的错误信息：docker: error while loading shared libraries: libltdl.so.7: cannot open shared object file: No such file or directory
第一次使用的docker部署jenkins的时候，出现了两个问题：
1、因为用户权限问题挂载/home/jenkins/data到/var/jenkins_home挂载不了。后面通过修改data目录的所属用户可以解决，即在容器下查询用户id（1000）,然后把data改成同样的用户id
2、即便挂载docker命名和docker.sock,也修改了相应的权限，仍存在libltdl7没有权限读取。当然好像也不影响使用，只是在容器里面执行docker info的时候，会报无法读取libltdl.so.7的信息。
docker: error while loading shared libraries: /usr/lib/x86_64-linux-gnu/libltdl.so.7: cannot read file data: Error 21
于是查找资料在jenkins/jenkins基础上再建一个Jenkins镜像。
编辑Dockerfile
FROM jenkins/jenkins:lts

USER root
#清除了基础镜像设置的源，切换成阿里云的jessie源
RUN echo &#39;&#39; &gt; /etc/apt/sources.list.d/jessie-backports.list \
  &amp;&amp; echo &quot;deb http://mirrors.aliyun.com/debian jessie main contrib non-free&quot; &gt; /etc/apt/sources.list \
  &amp;&amp; echo &quot;deb http://mirrors.aliyun.com/debian jessie-updates main contrib non-free&quot; &gt;&gt; /etc/apt/sources.list \
  &amp;&amp; echo &quot;deb http://mirrors.aliyun.com/debian-security jessie/updates main contrib non-free&quot; &gt;&gt; /etc/apt/sources.list
#更新源并安装缺少的包

RUN apt-get update &amp;&amp; apt-get install -y libltdl7

ARG dockerGid=999

RUN echo &quot;docker:x:${dockerGid}:jenkins&quot; &gt;&gt; /etc/group USER jenkins

# 安装 docker-compose  --- 挂载宿主机上的就可以了
# RUN curl -L https://github.com/docker/compose/releases/download/1.17.1/docker-compose-`uname -s`-`uname -m` -o /usr/local/bin/docker-compose
# RUN chmod +x /usr/local/bin/docker-compose
build镜像
docker build . -t myjenkins:v1
使用该镜像
</div>
        </div>
      </a>

      <div>
        
          <i class="iconfont icon-riqi2"></i>&nbsp;2020-01-09&nbsp;&nbsp;
        
        
          <i class="iconfont icon-inbox"></i>
          
            <a href="/categories/CI/CD">CI/CD</a>&nbsp;
          &nbsp;
        
        
          <i class="iconfont icon-tag"></i>
          
            <a href="/tags/docker">docker</a>&nbsp;
          
            <a href="/tags/jenkins">jenkins</a>&nbsp;
          
            <a href="/tags/CI/CD">CI/CD</a>&nbsp;
          
        
      </div>
    </div>
  </div>

  <div class="row mb-4 mx-auto">
    
    
      <div class="col-12 col-md-4 m-auto">
        <a href="/2020/01/09/Apache-Airflow%E4%BD%BF%E7%94%A8%E6%8C%87%E5%8D%97/" target="_self">
          <img src="https://i.loli.net/2020/01/09/6Ud8BfsPjZgoVrS.png" srcset="/img/loading.gif" alt="Apache Airflow使用指南" class="img-fluid rounded z-depth-3 index-thumbnails">
        </a>
      </div>
    
    <div class="col-12 col-md-8 m-auto">
      <a href="/2020/01/09/Apache-Airflow%E4%BD%BF%E7%94%A8%E6%8C%87%E5%8D%97/">
        <p class="h4 index-header">Apache Airflow使用指南</p>
        
        
          
        
        <div class="index-excerpt" >
          <div class="index-text mb-1">前言airflow 是 apache下孵化项目，是纯 Python 编写的一款非常优雅的开源调度平台。github 上有 8971 个星，是非常受欢迎的调度工具。airflow 使用 DAG (有向无环图) 来定义工作流，配置作业依赖关系非常方便，豪不夸张地说：方便程度简直甩其他任务调度工具一条街。 airflow 有着以下天然优势：

灵活易用，airflow 本身是 Python 编写的，且工作流的定义也是 Python 编写，有了 Python 胶水的特性，没有什么任务是调度不了的，有了开源的代码，没有什么问题是无法解决的，你完全可以修改源码来满足个性化的需求，而且更重要的是代码都是 –human-readable 。
功能强大，自带的 Operators 都有15+，也就是说本身已经支持 15+ 不同类型的作业，而且还是可自定义 Operators，什么 shell 脚本，python，mysql，oracle，hive等等，无论不传统数据库平台还是大数据平台，统统不在话下，对官方提供的不满足，完全可以自己编写 Operators。
优雅，作业的定义很简单明了, 基于 jinja 模板引擎很容易做到脚本命令参数化，web 界面更是也非常 –human-readable 。
极易扩展，提供各种基类供扩展, 还有多种执行器可供选择，其中 CeleryExcutor 使用了消息队列来编排多个工作节点(worker), 可分布式部署多个 worker ，airflow 可以做到无限扩展。
丰富的命令工具，你甚至都不用打开浏览器，直接在终端敲命令就能完成测试，部署，运行，清理，重跑，追数等任务。

airflow 是免费的，可以将一些常做的巡检任务，定时脚本（如 crontab ），ETL处理，监控等任务放在 airflow 上集中管理，甚至都不用再写监控脚本，作业出错会自动发送日志到指定人员邮箱，低成本高效率地解决生产问题。
组成部分从一个使用者的角度来看，调度工作都有以下功能：

系统配置（$AIRFLOW_HOME/airflow.cfg）
作业管理（$AIRFLOW_HOME/dags/xxxx.py）
运行监控（webserver)
报警（邮件或短信）
日志查看（webserver 或 $AIRFLOW_HOME/logs/***)
跑批耗时分析（webserver)
后台调度服务（scheduler)

除了短信需要自己实现，其他功能 airflow 都有，而且在 airflow 的 webserver 上我们可以直接配置数据库连接来写 sql 查询，做更加灵活的统计分析。
重要概念DAGLinux 的 crontab 和 windows 的任务计划，他们可以配置定时任务或间隔任务，但不能配置作业之前的依赖关系。airflow 中 DAG 就是管理作业依赖关系的。DAG 的英文 directed acyclic graphs 即有向无环图，下图 1 便是一个简单的 DAG
在 airflow 中这种 DAG 是通过编写 Python 代码来实现的，DAG 的编写非常简单，官方提供了很多的例子，在安装完成后，启动 webserver 即可看到 DAG 样例的源码（其实定义了 DAG 对象的 python 程序），稍做修改即可成为自己的 DAG 。上图 1 中 DAG 中的依赖关系通过下述三行代码即可完成：
Operators-操作符DAG 定义一个作业流，Operators 则定义了实际需要执行的作业。airflow 提供了许多 Operators 来指定我们需要执行的作业：

BashOperator - 执行 bash 命令或脚本。
SSHOperator - 执行远程 bash 命令或脚本（原理同 paramiko 模块）。
PythonOperator - 执行 Python 函数。
EmailOperator - 发送 Email。
HTTPOperator - 发送一个 HTTP 请求。
MySqlOperator, SqliteOperator, PostgresOperator, MsSqlOperator, OracleOperator, JdbcOperator, 等. - 执行 SQL 任务。
DockerOperator, HiveOperator, S3FileTransferOperator, PrestoToMysqlOperator, SlackOperator 等。

除了以上这些 Operators 还可以方便的自定义 Operators 满足个性化的任务需求。后续会介绍如何使用这些 Operators。
Timezone-时区airflow 1.9 之前的版本使用本地时区来定义任务开始日期，scheduler_interval 中 crontab 表达式中的定时也是依据本地时区为准，但 airflow 1.9 及后续新版本将默认使用 UTC 时区来确保 airflow 调度的独立性，以避免不同机器使用不同时区导致运行错乱。如果调度的任务集中在一个时区上，或不同机器，但使用同一时区时，需要对任务的开始时间及 cron 表达式进行时区转换，或直接使用本地时区。目前 1.9 的稳定版本还不支持时区配置，后续版本会加入时区配置，以满足使用本地时区的需求。
Webserver-Web服务器webserver 是 airflow 的界面展示，可显示 DAG 视图，控制作业的启停，清除作业状态重跑，数据统计，查看日志，管理用户及数据连接等。不运行 webserver 并不影响 airflow 作业的调度。
Schduler-调度器调度器 schduler 负责读取 DAG 文件，计算其调度时间，当满足触发条件时则开启一个执行器的实例来运行相应的作业，必须持续运行，不运行则作业不会跑批。
Worker-工作节点当执行器为 CeleryExecutor 时，需要开启一个 worker。
Executor-执行器执行器有 SequentialExecutor, LocalExecutor, CeleryExecutor

SequentialExecutor 为顺序执行器，默认使用 sqlite 作为知识库，由于 sqlite 数据库的原因，任务之间不支持并发执行，常用于测试环境，无需要额外配置。
LocalExecutor 为本执行器，不能使用 sqlite 作为知识库，可以使用 mysql,postgress,db2,oracle 等各种主流数据库，任务之间支持并发执行，常用于生产环境，需要配置数据库连接 url。
CeleryExecutor 为 Celery 执行器，需要安装 Celery ,Celery 是基于消息队列的分布式异步任务调度工具。需要额外启动工作节点-worker。使用 CeleryExecutor 可将作业运行在远程节点上。


基于Docker搭建基于第三方docker镜像进行安装，github-repo：https://github.com/puckel/docker-airflow
前提：机器已经装上docker及docker-compose命令，本页面基于Docker搭建，部署airflow的CeleryExecutor模式

Step1 拉取代码
git clone https://github.com/puckel/docker-airflow.git

Step2 修改 docker-compose-CeleryExecutor.yml及Dockerfile
cd ~/docker-airflow
vim docker-compose-CeleryExecutor.yml默认的compose是抓原来版本的镜像包，改成latest标签，这样才会使用用Dockerfile构建的镜像
修改web暴露端口，8080可能被占用，下图修改为8096端口



Step3 Airflow Config设置
cd config
vim airflow.cfg


构建镜像
docker build --rm -t puckel/docker-airflow:latest .
docker-compose -f docker-compose-CeleryExecutor.yml up -d


当看到下图，就代表已经启动，可通过该端口进行访问
</div>
        </div>
      </a>

      <div>
        
          <i class="iconfont icon-riqi2"></i>&nbsp;2020-01-09&nbsp;&nbsp;
        
        
          <i class="iconfont icon-inbox"></i>
          
            <a href="/categories/etl">etl</a>&nbsp;
          &nbsp;
        
        
          <i class="iconfont icon-tag"></i>
          
            <a href="/tags/docker">docker</a>&nbsp;
          
            <a href="/tags/etl">etl</a>&nbsp;
          
            <a href="/tags/apache%20airflow">apache airflow</a>&nbsp;
          
        
      </div>
    </div>
  </div>

  <div class="row mb-4 mx-auto">
    
    
      <div class="col-12 col-md-4 m-auto">
        <a href="/2020/01/09/Apache-Nifi%E4%BD%BF%E7%94%A8%E6%8C%87%E5%8D%97/" target="_self">
          <img src="https://i.loli.net/2020/01/09/6E4IuLwCiAm15KW.png" srcset="/img/loading.gif" alt="Apache Nifi使用指南" class="img-fluid rounded z-depth-3 index-thumbnails">
        </a>
      </div>
    
    <div class="col-12 col-md-8 m-auto">
      <a href="/2020/01/09/Apache-Nifi%E4%BD%BF%E7%94%A8%E6%8C%87%E5%8D%97/">
        <p class="h4 index-header">Apache Nifi使用指南</p>
        
        
          
        
        <div class="index-excerpt" >
          <div class="index-text mb-1">简介Apache NiFi是什么？NiFi官网给出如下解释：“一个易用、强大、可靠的数据处理与分发系统”。通俗的来说，即Apache NiFi 是一个易于使用、功能强大而且可靠的数据处理和分发系统，其为数据流设计，它支持高度可配置的指示图的数据路由、转换和系统中介逻辑。
架构单节点架构

集群架构图

web-sever
其目的在于提供基于HTTP的命令和控制API。
Flow Controller
这是操作的核心，以Processor为处理单元，提供了用于运行的扩展线程，并管理扩展接收资源时的调度。
Extensions
在其他文档中描述了各种类型的NiFi扩展，Extensions的关键在于扩展在JVM中操作和执行。
FlowFile Repository
FlowFile库的作用是NiFi跟踪记录当前在流中处于活动状态的给定流文件的状态，其实现是可插拔的，默认的方法是位于指定磁盘分区上的一个持久的写前日志。FlowFile库的作用是NiFi跟踪记录当前在流中处于活动状态的给定流文件的状态，其实现是可插拔的，默认的方法是位于指定磁盘分区上的一个持久的写前日志。
Content Repository
Content库的作用是给定流文件的实际内容字节所在的位置，其实现也是可插拔的。默认的方法是一种相对简单的机制，即在文件系统中存储数据块。
Provenance Repository
Provenance库是所有源数据存储的地方，支持可插拔。默认实现是使用一个或多个物理磁盘卷，在每个位置事件数据都是索引和可搜索的。
docker部署nifi需要通过集群实现多租户，在standalone模式下，可以通过docker启动多个实例来实现多用户通过不同端口访问各自的nifi
docker run --name nifi01 \
  --restart=always \
  -p 8090:8080 \
  -p 10000:10000 \
  -v /data/nifi:/data/nifi/ \
  -d \
  apache/nifi:latest

  docker run --name nifi02 \
  --restart=always \
  -p 8094:8080 \
  -p 10001:10000 \
  -v /data/nifi02:/data/nifi02/ \
  -d \
  apache/nifi:latest
启动nifi，停止nifi
docker start nifi
docker stop nifi
NiFi ProcessorFlow Controller是NiFi的核心，Flow Controller扮演者文件交流的处理器角色，维持着多个处理器的连接并管理各个Processer，Processor则是实际处理单元。

Processor包含各种类型的组件，如amazon、attributes、hadoop等，可通过前缀进行轻易辨识，如Get、Fetch开头代表获取，如getFile、getFTP、FetchHDFS，execute代表执行，如ExecuteSQL、ExecuteProcess、ExecuteFlumeSink等均可较容易知其简单用途。右边选择hadoop则会显示所有hadoop相关的processor，如图所示

与hadoop相关的processor有读写HDFS文件，写Hbase，读写parquet文件等
Nifi实战Demo通过Nifi实现把指定文件夹中的文件移动到另一个文件夹
step 1选取processor
选取getfile及putfile的process，并连接





step 2 填写getfile及putfile相关属性
双击getfile或者putfile的processor，property中填写源数据文件夹及目标文件夹，其他参数按需进行配置，此demo按照默认参数填写，对于putfile processor中的setting栏，设置勾选自动终止策略，当putfile失败或者成功的时候就停止此processor






step 3 启动
空白处右键选择start，状态栏显示绿色代表processor在执行，假如/data/nifi/input有文件此时开启工作流后/data/nifi/input对应也会有该文件



数据库表和表同步表到表的同步,NIFI默认sql查询出来的数据为Avro格式,所以需要先将Avro格式转化为json格式,再将json转换为sql语句,最后使用PUTSQL处理器将数据存入数据库。需要用到ExecuteorSQL、ConvertAvroToJSON、ConvertJSONToSQL、PUTSQL四种处理器。 

step 1 使用ExecuteSQL配置数据源从Components ToolBar上将processor拖拽到画布上，选择ExecuteSQL处理器，右键或双击该处理器编辑properties。该处理器原生提供三种数据库连接池，提供了大多数数据库驱动，另外还可以自定义连接池的名称。
Database Connection Pooling Service 提供数据库连接池服务  
postgresql驱动程序下载
驱动配置完成后点击⚡,使能后查看是否报错  


step 2 使用ConvertAvroToJSON将Avro格式转换为json格式
step 3 使用ConvertJSONToSQL将json数据转换为SQL语句 
step 4 使用PUTSQL将数据存入到数据库，配置完成后数据流启动后可以看到数据流动过程，再到数据库中验证结果。

Tips:基本案例跑通后可以在Operate栏createTemplate,可以在web页面直接导出xml格式的数据处理流程重复使用减少配置时间。  
Trouble Shooting
原始文件夹或者目标文件夹没有权限，process右上角会显示报错信息，此时应该将文件夹设置对应权限，将拥有者改为nifi用户，此命令应该用root权限执行，若nifi在docker中，应该到使用root用户登录到对应container执行

linux版本
sudo chown -R nifi:nifi /data/nifi/input
sudo chown -R nifi:nifi /data/nifi/output
docker版本
docker exec -it -u root nifi /bin/bash
chown -R nifi:nifi /data/nifi/input
chown -R nifi:nifi /data/nifi/output报错信息：


putfile或者getfile的properties填写错误的时候，对应processor上面会显示感叹号，按照提示修改即可，如getfile中源文件夹为/data/nifi/input01，系统中没有此文件夹，则会显示对应提示信息


</div>
        </div>
      </a>

      <div>
        
          <i class="iconfont icon-riqi2"></i>&nbsp;2020-01-09&nbsp;&nbsp;
        
        
          <i class="iconfont icon-inbox"></i>
          
            <a href="/categories/etl">etl</a>&nbsp;
          &nbsp;
        
        
          <i class="iconfont icon-tag"></i>
          
            <a href="/tags/docker">docker</a>&nbsp;
          
            <a href="/tags/apache%20nifi">apache nifi</a>&nbsp;
          
            <a href="/tags/etl">etl</a>&nbsp;
          
        
      </div>
    </div>
  </div>

  <div class="row mb-4 mx-auto">
    
    
      <div class="col-12 col-md-4 m-auto">
        <a href="/2020/01/09/Spark-run-on-K8s/" target="_self">
          <img src="https://i.loli.net/2020/01/09/yfu8QZc7i3sRdrU.png" srcset="/img/loading.gif" alt="Spark run on K8s" class="img-fluid rounded z-depth-3 index-thumbnails">
        </a>
      </div>
    
    <div class="col-12 col-md-8 m-auto">
      <a href="/2020/01/09/Spark-run-on-K8s/">
        <p class="h4 index-header">Spark run on K8s</p>
        
        
          
        
        <div class="index-excerpt" >
          <div class="index-text mb-1">部署首先查看了下spark的官方文档，了解了spark怎么在k8s上面跑的，实际上不需要搭建spark集群，提交作业到k8s的api server即可。看似简单但是还是不知道怎么动手实践。于是youtube上面搜了下相关视频，按照视频很快就实践了一把spark run on k8s，具体步骤如下：

step 1 到k8-master机器下载二进制spark最新二进制安装包，并解压

cd /opt
wget http://mirrors.tuna.tsinghua.edu.cn/apache/spark/spark-2.4.4/spark-2.4.4-bin-hadoop2.7.tgz
tar -zxvf http://mirrors.tuna.tsinghua.edu.cn/apache/spark/spark-2.4.4/spark-2.4.4-bin-hadoop2.7.tgz

step 2 制作spark的docker镜像

cd spark-2.4.4-bin-hadoop2.7
./bin/docker-image-tool.sh -r chenlianguu -t v2.4.4 build  # 制作spark进行
./bin/docker-image-tool.sh -r chenlianguu -t v2.4.4 push  #将spark镜像推送到docker hub
docker images
[root@k8s-master opt]# docker images
REPOSITORY                                                        TAG                 IMAGE ID            CREATED             SIZE
chenliang/spark-r                                                 v2.4.4              6479a523e3f7        20 hours ago        759MB


step 3 提交作业到k8s

在提交spark的作业的机器上，把api server的proxy打开
kubectl proxy
./bin/spark-submit \
--master k8s://http://127.0.0.1:8001 \
--name spark-pi \
--deploy-mode cluster \
--class org.apache.spark.examples.SparkPi \
--conf spark.executor.instances=3 \
--conf spark.kubernetes.container.image=chenlianguu/spark-r:v2.4.4 \
/opt/spark-2.4.4-bin-hadoop2.7/examples/jars/spark-examples_2.11-2.4.4.jar
运行说明集群模式下，通过spark-submit提交程序到k8s集群，具体一下步骤：  

通过k8s创建spark driver端的pod
driver端在k8s其他节点创建executor端的pod并保持通信，executor具体执行代码，这里设计到权限问题，假如没有对应的权限创建pods，执行spark会报错，具体见trouble  shooting第二点
当程序跑完了，executor端pod会终止并清理，driver端的pod会保持complete状态并持久化log信息，最后会由k8s api server进行driver端pod的垃圾回收工作

trouble shooting跑spark on k8s的pi example碰到的一些坑及解决方案

找不到jar问题之前提交的脚本是这样的  

./bin/spark-submit \
--master k8s://http://127.0.0.1:8001 \
--name spark-pi \
--deploy-mode cluster \
--class org.apache.spark.examples.SparkPi \
--conf spark.executor.instances=3 \
--conf spark.kubernetes.container.image=chenlianguu/spark-r:v2.4.4 \
/opt/spark-2.4.4-bin-hadoop2.7/examples/jars/spark-examples_2.11-2.4.4.jar
其中jar包制定的地址是local，路径填写应该加上协议local:///opt/spark-2.4.4-bin-hadoop2.7/examples/jars/spark-examples_2.11-2.4.4.jar，加上之后还是报同样的错，google后发现jar包实际上是在jar包在docker镜像里面的地址，因此改为local:///opt/spark/examples/jars/spark-examples_2.11-2.4.4.jar   

jar问题解决了，又开始报错，报错信息如下第一感觉就是权限问题，网上找到了解决方案，ref：解决办法，按照这个思路，在k8s-master节点，输入   kubectl create clusterrolebinding default --clusterrole cluster-admin --serviceaccount=default:default

然后继续执行spark-submit脚本，可以顺利启动driver端，但是有2个executor端还是报错，说是资源不够，有一个executor端执行成功，整个job还是顺利的跑下来了，查看driver端日志。kubectl logs podsname 
参考资料：spark官方docyoutube动手视频
</div>
        </div>
      </a>

      <div>
        
          <i class="iconfont icon-riqi2"></i>&nbsp;2020-01-09&nbsp;&nbsp;
        
        
          <i class="iconfont icon-inbox"></i>
          
            <a href="/categories/kubernetes">kubernetes</a>&nbsp;
          &nbsp;
        
        
          <i class="iconfont icon-tag"></i>
          
            <a href="/tags/kubernetes">kubernetes</a>&nbsp;
          
            <a href="/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE">大数据</a>&nbsp;
          
            <a href="/tags/%E9%83%A8%E7%BD%B2">部署</a>&nbsp;
          
            <a href="/tags/spark">spark</a>&nbsp;
          
        
      </div>
    </div>
  </div>

  <div class="row mb-4 mx-auto">
    
    
      <div class="col-12 col-md-4 m-auto">
        <a href="/2020/01/09/Kubernetes%E9%83%A8%E7%BD%B2/" target="_self">
          <img src="https://www.ovh.com/blog/wp-content/uploads/2019/01/kubernetesblog02.jpg" srcset="/img/loading.gif" alt="Kubernetes部署" class="img-fluid rounded z-depth-3 index-thumbnails">
        </a>
      </div>
    
    <div class="col-12 col-md-8 m-auto">
      <a href="/2020/01/09/Kubernetes%E9%83%A8%E7%BD%B2/">
        <p class="h4 index-header">Kubernetes部署</p>
        
        
          
        
        <div class="index-excerpt" >
          <div class="index-text mb-1">k8s的搭建主要有三种方式：kubeadmin安装、docker安装及二进制安装，其中二进制安装方式最为复杂需要部署人员了解网络https，ca证书等方面的知识，kubeadmin安装方式大大简化了部署操作，刚入门建议尝试kubeadmin方式安装。docker安装我并不觉得合适，本身k8s作为容器编排系统部署在docker里面，网络及相关端口配置较为复杂，为了避免埋下太多的坑，本人没有尝试这种方式进行安装。
具体安装部署我就不写在这里了，分享一套自己看的k8s入门视频，很简短能够快速了解k8s，当时k8s学习曲线是比较陡峭的。
👉🏻百度云盘 密码:amlo
👉🏻安装部署文档  
按照此文档部署基本没啥坑，注意的是部分镜像在国外服务器，需要替换成文档作者国内的镜像即可。

最近看到新的工具rancher，企业级管理运维kubernetes集群的好工具的。后续继续更新
</div>
        </div>
      </a>

      <div>
        
          <i class="iconfont icon-riqi2"></i>&nbsp;2020-01-09&nbsp;&nbsp;
        
        
          <i class="iconfont icon-inbox"></i>
          
            <a href="/categories/kubernetes">kubernetes</a>&nbsp;
          &nbsp;
        
        
          <i class="iconfont icon-tag"></i>
          
            <a href="/tags/kubernetes">kubernetes</a>&nbsp;
          
            <a href="/tags/%E9%83%A8%E7%BD%B2">部署</a>&nbsp;
          
        
      </div>
    </div>
  </div>

  <div class="row mb-4 mx-auto">
    
    
      <div class="col-12 col-md-4 m-auto">
        <a href="/2020/01/09/Docker%E9%83%A8%E7%BD%B2%E4%BC%AA%E5%88%86%E5%B8%83%E5%BC%8F%E5%A4%A7%E6%95%B0%E6%8D%AE%E7%8E%AF%E5%A2%83/" target="_self">
          <img src="https://i.loli.net/2020/01/09/6FDoa7m5WTCnGg2.jpg" srcset="/img/loading.gif" alt="Docker部署伪分布式大数据环境" class="img-fluid rounded z-depth-3 index-thumbnails">
        </a>
      </div>
    
    <div class="col-12 col-md-8 m-auto">
      <a href="/2020/01/09/Docker%E9%83%A8%E7%BD%B2%E4%BC%AA%E5%88%86%E5%B8%83%E5%BC%8F%E5%A4%A7%E6%95%B0%E6%8D%AE%E7%8E%AF%E5%A2%83/">
        <p class="h4 index-header">Docker部署伪分布式大数据环境</p>
        
        
          
        
        <div class="index-excerpt" >
          <div class="index-text mb-1">思路通过docker搭建大数据环境  

开箱即用，不常驻后台，需要的时候启动集群即可，不用的时候关闭集群释放机器资源
避免了直接安装端口占用问题，大数据平台所需端口较多
spark资源docker化，便于后期k8s进行资源管理调度

上述好处主要是基于测试环境下，基于生产环境的大数据平台化要考虑的点很多，例如后期扩容、运维、安全等因素，大数据平台整个是否docker化后期有待考证。
镜像制作方案使用Docker来搭建hadoop,spark及mysql的集群，首先使用Dockerfile制作镜像，把相关的软件拷贝到约定好的目录 下，把配置文件在外面先配置好，再拷贝移动到hadoop,spark的配置目录，为了能使得mysql能从其它节点被访问到，要配置mysql的访问权限。
整体架构一共3个节点，即启动3个容器。hadoop-master,hadoop-node1,hadoop-node2这三个容器里面安装hadoop和spark集群。
集群部署集群网络规划及子网配置既然是做集群，网络的规划是少不了的,至于网络，可以通过Docker中的DockerNetworking的支持配置。首先设置网络，docker中设置 子网可以通过docker network create 方法，这里我们通过命令设置如下的子网。–subnet指定子网络的网段，并为这个子网命名一个名字叫spark
# 创建子网
docker network create --subnet=172.16.0.0/16 spark
# 查看网络
docker network ls
NETWORK ID          NAME                       DRIVER              SCOPE
fab2dd51d1cf        spark                      bridge              local
 接下来就在我们创建的子网落spark中规划集群中每个容器的ip地址。网络ip分配如下:
hadoop-master 172.16.0.2
hadoop-node1 172.16.0.3
hadoop-node2 172.16.0.4
软件版本网络规划好了，首先Spark我们使用最新的2.4.4版本，Hadoop采用比较稳定的hadoop-2.7.3版本，scala采用scala-2.11.8，JDK采用jdk-8u101-linux-x64。
SSH无密钥登录规则配置注意这里不使用ssh-keygen -t rsa -P ‘’这种方式生成id_rsa.pub，然后集群节点互拷贝id_rsa.pub到authorized_keys文件这种方式，而 是通过在.ssh目录下配置ssh_conf文件的方式，ssh_conf中可以配置SSH的通信规则，例如以正则表达式的方式指定hostname为XXX的 机器之间实现互联互通，而不进行额外的密钥验证。为了编写这个正则表达式，我们5个节点的hostname都以hadoop-*的方式作为开 头，这就是采用这种命名规则的原因。下面来看下ssh_conf配置的内容:
Host localhost
    StrictHostKeyChecking no
Host 0.0.0.0 
    StrictHostKeyChecking no
Host hadoop-* 
    StrictHostKeyChecking no
注意上面的最后一行，Host hadoop-* 指定了它的严格的Host验证StrictHostKeyChecking 为no，这样既可以是这5个hostname以 hadoop-*开头的容器之间实现互联互通，而不需要二外的验证。
构建镜像Dockerfile编写完成，接下来写一个build.sh脚本，内容如下:
 echo build hadoop images
 docker build -t=&quot;spark&quot; . 
表示构建一个名叫spark的镜像，.表示Dockerfile的路径，因为在当前路径下，所有用.,若在其他地方则用绝对路径指定Dockerfile的路径 即可。
运行sh build.sh，就会开始制作镜像了。
集群运行启动容器 start_container.sh使用这个镜像可完成容器的启动，因为使用了基于DockerNetworking的网络机制，因此可以在启动容器的时候为容器在子网172.16.0.0/16 spark中分贝172.16.0.1 172.16.0.255以外的IP地址，容器内部容器的通信是基于hostname，因此 需要指定hostname，为了方便容器的管理，需要为启动的每个容器指定一个名字。为了方便外网访问，需要通过-p命令指定容器到宿主机的端口映射。还要为每个容器增加host列表。
# hadoop-master
docker run -itd --restart=always \
    --net spark \
    --ip 172.16.0.2 \
    --privileged \
    -p 18032:8032 \
    -p 28080:18080 \
    -p 29888:19888 \
    -p 17077:7077 \
    -p 51070:50070 \
    -p 18888:8888 \
    -p 19000:9000 \
    -p 11100:11000 \
    -p 51030:50030 \
    -p 18050:8050 \
    -p 18081:8081 \
    -p 18900:8900 \
    --name hadoop-master \
    --hostname hadoop-master \
    --add-host hadoop-node1:172.16.0.3 \
    --add-host hadoop-node2:172.16.0.4 \
    --add-host hadoop-mysql:172.16.0.6 \
    spark /usr/sbin/init

# hadoop-node1
docker run -itd --restart=always \
    --net spark \
    --ip 172.16.0.3 \
    --privileged \
    -p 18042:8042 \
    -p 51010:50010 \
    -p 51020:50020 \
    --name hadoop-node1 \
    --hostname hadoop-node1 \
    --add-host hadoop-master:172.16.0.2 \
    --add-host hadoop-node2:172.16.0.4 \
    spark /usr/sbin/init

# hadoop-node2
docker run -itd --restart=always \
    --net spark \
    --ip 172.16.0.4 \
    --privileged \
    -p 18043:8042 \
    -p 51011:50011 \
    -p 51021:50021 \
    --name hadoop-node2 \
    --hostname hadoop-node2 \
    --add-host hadoop-master:172.16.0.2 \
    --add-host hadoop-node1:172.16.0.3 \
    spark /usr/sbin/init

关闭集群 stop_container.shecho stop containers
docker stop hadoop-master
docker stop hadoop-node1
docker stop hadoop-node2
echo remove containers
docker rm hadoop-master
docker rm hadoop-node1
docker rm hadoop-node2

echo rm containers

docker ps
重启集群 restart_container.shecho stop containers
docker stop hadoop-master
docker stop hadoop-node1
docker stop hadoop-node2
echo restart containers
docker start hadoop-master
docker start hadoop-node1
docker start hadoop-node2
echo start sshd
docker exec -it hadoop-master systemctl start sshd
docker exec -it hadoop-node1 systemctl start sshd
docker exec -it hadoop-node2 systemctl start sshd
docker exec -it hadoop-master ~/restart-hadoop.sh
echo  containers started

docker ps
Trouble Shooting
docker里面执行systemctl报错
解决方案：启动的时候用/usr/sbin/init

docker登录harbor报错window直接修改docker设置，添加52.83.79.244:8093到docker insecure registrylinux修改方法：https://blog.csdn.net/u010397369/article/details/42422243  


Demo进入hadoop-master容器内部，执行spark-shell
root@node-2 docker-spark]# docker exec -it hadoop-master /bin/bash
[root@hadoop-master ~]# spark
spark-class   spark-shell   spark-sql     spark-submit  sparkR
[root@hadoop-master ~]# spark-shell
19/12/03 04:51:25 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Setting default log level to &quot;WARN&quot;.
To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).
19/12/03 04:51:43 WARN util.Utils: spark.executor.instances less than spark.dynamicAllocation.minExecutors is invalid, ignoring its setting, please update your configs.
Spark context Web UI available at http://hadoop-master:4040
Spark context available as &#39;sc&#39; (master = spark://hadoop-master:7077, app id = app-20191203045141-0000).
Spark session available as &#39;spark&#39;.
Welcome to
      ____              __
     / __/__  ___ _____/ /__
    _\ \/ _ \/ _ `/ __/  &#39;_/
   /___/ .__/\_,_/_/ /_/\_\   version 2.4.4
      /_/

Using Scala version 2.11.12 (Java HotSpot(TM) 64-Bit Server VM, Java 1.8.0_101)
Type in expressions to have them evaluated.
Type :help for more information.

scala&gt;
本地部署
想要在自己的笔记本环境使用
首先笔记本环境下需要有docker环境

拉取gitlab上面的项目：git clone git@161.189.27.8:chenliang/docker-spark.git
拉去harbor上面的镜像：docker pull 52.83.79.244:8093/wuhan/spark:v1（也可以自己构建镜像，Dockerfile文件在gitlab项目里边）  前提：机器docker环境登录harbor，账号密码：admin 1qaz!QAZdocker login 52.83.79.244:8093登录报错：Error response from daemon: Get https://52.83.79.244:8093/v2/: http: server gave HTTP response to HTTPS client解决：参见trouble shooting
使用相关脚本执行启动、停止、重启集群




如何自己的spark程序如何在docker环境下执行  
启动spark的集群之后，使用docker cp等命令将打好的jar包打进容器内，使用spark脚本执行


</div>
        </div>
      </a>

      <div>
        
          <i class="iconfont icon-riqi2"></i>&nbsp;2020-01-09&nbsp;&nbsp;
        
        
          <i class="iconfont icon-inbox"></i>
          
            <a href="/categories/%E8%BF%90%E7%BB%B4">运维</a>&nbsp;
          &nbsp;
        
        
          <i class="iconfont icon-tag"></i>
          
            <a href="/tags/docker">docker</a>&nbsp;
          
            <a href="/tags/%E7%8E%AF%E5%A2%83">环境</a>&nbsp;
          
            <a href="/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE">大数据</a>&nbsp;
          
            <a href="/tags/%E9%83%A8%E7%BD%B2">部署</a>&nbsp;
          
        
      </div>
    </div>
  </div>

  <div class="row mb-4 mx-auto">
    
    
      <div class="col-12 col-md-4 m-auto">
        <a href="/2020/01/09/Docker%E9%83%A8%E7%BD%B2Nextcloud/" target="_self">
          <img src="https://i.loli.net/2020/01/09/6Wies2vuV8bdrLm.png" srcset="/img/loading.gif" alt="Docker部署Nextcloud" class="img-fluid rounded z-depth-3 index-thumbnails">
        </a>
      </div>
    
    <div class="col-12 col-md-8 m-auto">
      <a href="/2020/01/09/Docker%E9%83%A8%E7%BD%B2Nextcloud/">
        <p class="h4 index-header">Docker部署Nextcloud</p>
        
        
          
        
        <div class="index-excerpt" >
          <div class="index-text mb-1">准备工作docker的安装及配置# 通过yum安装
yum install -y docker-ce
# 启动docker并设置开机启动
systemctl start docker
systemctl enable docker
# aws ec2 linux2另外一种安装方式
sudo amazon-linux-extras install docker
sudo service docker start
由于docker镜像源默认是在国外，拉取镜像速度非常慢，修改daemon配置文件/etc/docker/daemon.json来使用加速器
mkdir -p /etc/docker
touch /etc/docker/daemon.json
vim /etc/docker/daemon.json
{
  &quot;registry-mirrors&quot;: [&quot;https://b3sst9pc.mirror.aliyuncs.com&quot;]
}
systemctl daemon-reload
systemctl restart docker
docker-compose安装Docker Compose是 docker 提供的一个命令行工具，用来定义和运行由多个容器组成的应用。使用 compose，我们可以通过 YAML 文件声明式的定义应用程序的各个服务，并由单个命令完成应用的创建和启动。

docker-compose命令安装
# 安装pip
yum -y install epel-release
yum -y install python-pip
# 确认版本
pip --version
# 更新pip
pip install --upgrade pip
# 安装docker-compose
pip install docker-compose 
# 查看版本
docker-compose version


nextcloud的部署nextcloud通过docker-compose命令进行构建，创建 docker-compose.yml文件
# 创建docker-compose.yml文件
touch docker-compose.yml
# 粘贴以下内容
version: &#39;2&#39;
services:
  db:
    image: mariadb
    restart: always
    volumes:
      - /data/mariadb:/var/lib/mysql
    environment:
      - MYSQL_ROOT_PASSWORD=root
      - MYSQL_PASSWORD=nextcloud
      - MYSQL_DATABASE=nextcloud
      - MYSQL_USER=nextcloud

  app:
    image: nextcloud
    restart: always
    ports:
      - 8091:80
    links:
      - db
    volumes:
      - /data/nextcloud/data:/var/www/html/data    
      - /data/nextcloud/themes:/var/www/html/themes
      - /data/nextcloud/apps:/var/www/html/custom_apps
docker-compose.yml文件说明
通过启动两个service服务mariadb及nextcloud服务，并通过link连接到一起，其中将/var/www/html/data、/var/www/html/themes、/var/www/html/custom_apps映射到linux服务器指定目录实现数据持久化，这样下次docker重启的时候数据不会发生丢失。
nextcloud实现预览编辑office文件需要插件onlyoffice支持，通过docker创建onlyoffice服务器，并启动nextcloud配置onlyoffice
docker run -it -d -p 8061:80 onlyoffice/documentserver  -v /data/onlyoffice/logs:/var/log/onlyoffice /data/onlyoffice/data:/var/www/onlyoffice/Data /data/onlyoffice/lib:/var/lib/onlyoffice /data/onlyoffice/db:/var/lib/postgresql
启动nextcloud、停止nextcloud、查看nextcloud启动状态
# 启动nextcloud
docker-compose up -d
# 查看nextcloud状态
docker-compose ps
# 停止nextcloud
docker-compose stop
nextcloud的数据迁移当需要nextcloud迁移到另外一台服务的时候，需要将nextcloud持久化的数据通过scp或者其他方式复制到另外一台机器，将原来的机器mariadb的nextcloud数据库进行导出，在新的机器上面导入数据库数据。复制YAML文件到新的机器，通过docker-compose进行启动，进入容器内部修改持久化数据的权限及修改nextcloud配置文件，最后重启容器。
# 复制持久化数据到新的机器上面
scp -R /data/nextcloud root@192.168.12.1:/data
# 导出原来机器的上面的mariadb数据
docker exec -it  nextcloud_db_1【docker容器名称/ID】 mysqldump -uroot -proot【数据库密码】 nextcloud【数据库名称】 &gt; /opt/sql_bak/nextcloud.sql【导出表格路径】
# 将sql文件复制到新的机器上面
scp  /opt/sql_bak/nextcloud.sql root@192.168.12.1:/opt/sql_bak
# 在新的机器上面执行该sql文件(需要先启动docker容器)
docker cp /opt/sql_bak/nextcloud.sql 【容器名】:/root/
docker exec -it 【容器名/ID】sh
mysql -uroot -p nextcloud【数据库名】 &lt; /root/nextcloud.sql
# 通过docker-compose启动镜像，修改权限
 docker exec -it -u root nextcloud_app_1【容器id/容器名】 /bin/bash
 root@bafc02ce112a:/var/www/html# chown -R www-data:root /var/www/html/
 root@bafc02ce112a:exit
# 修改nextcloud配置文件
vim /data/nextcloud/config/config.php
# 修改ip
&#39;trusted_domains&#39; =&gt;
  array (
    0 =&gt; &#39;161.189.27.8:8091&#39;,
  ),
  &#39;datadirectory&#39; =&gt; &#39;/var/www/html/data&#39;,
  &#39;dbtype&#39; =&gt; &#39;mysql&#39;,
  &#39;version&#39; =&gt; &#39;16.0.4.1&#39;,
  &#39;overwrite.cli.url&#39; =&gt; &#39;http://161.189.27.8:8091&#39;,
# 重启
docker-compose restart
trouble shooting
安装docker-compose命令执行pip install docker-compose的时候报以下错误
ERROR: Cannot uninstall &#39;requests&#39;. It is a distutils installed project and thus we cannot accurately determine which files belong to it which would lead to only a partial uninstall.解决版本，强制安装requests包
 pip install --ignore-installed requests
再重新执行
pip install docker-compose

docker-compose报错：No module named ssl_match_hostname
File &quot;/usr/local/lib/python2.7/dist-packages/docker/transport/ssladapter.py&quot;, line 23, in &lt;module&gt;
from backports.ssl_match_hostname import match_hostname
ImportError: No module named ssl_match_hostname原因：
/usr/local/lib/python2.7/distpackages/docker/transport/ssladapter.py **在包路径下找不到 **backports包里的ssl_match_hostname模块
解决办法
#进入backports模块路径
cd /usr/lib/python2.7/site-packages
#复制整个包到transport包路径下
cp -r backports /usr/lib/python2.7/site-packages/docker/transport


</div>
        </div>
      </a>

      <div>
        
          <i class="iconfont icon-riqi2"></i>&nbsp;2020-01-09&nbsp;&nbsp;
        
        
          <i class="iconfont icon-inbox"></i>
          
            <a href="/categories/%E8%BF%90%E7%BB%B4">运维</a>&nbsp;
          &nbsp;
        
        
          <i class="iconfont icon-tag"></i>
          
            <a href="/tags/docker">docker</a>&nbsp;
          
            <a href="/tags/nextcloud">nextcloud</a>&nbsp;
          
            <a href="/tags/%E7%BD%91%E7%9B%98">网盘</a>&nbsp;
          
            <a href="/tags/%E9%83%A8%E7%BD%B2">部署</a>&nbsp;
          
        
      </div>
    </div>
  </div>

  <div class="row mb-4 mx-auto">
    
    
      <div class="col-12 col-md-4 m-auto">
        <a href="/2020/01/09/Docker%E7%A7%81%E6%9C%8DHarbor%E4%BD%BF%E7%94%A8%E6%8C%87%E5%8D%97/" target="_self">
          <img src="https://i.loli.net/2020/01/09/LKEbkBZWwV7rRT1.jpg" srcset="/img/loading.gif" alt="Docker私服Harbor使用指南" class="img-fluid rounded z-depth-3 index-thumbnails">
        </a>
      </div>
    
    <div class="col-12 col-md-8 m-auto">
      <a href="/2020/01/09/Docker%E7%A7%81%E6%9C%8DHarbor%E4%BD%BF%E7%94%A8%E6%8C%87%E5%8D%97/">
        <p class="h4 index-header">Docker私服Harbor使用指南</p>
        
        
          
        
        <div class="index-excerpt" >
          <div class="index-text mb-1">harbor搭建官方提供两种方式安装harbor，离线及在线方式。本文档描述离线方式进行安装
查看docker-compose版本，若版本低进行升级安装，
下载官方安装包
cd /opt
wget https://storage.googleapis.com/harbor-releases/release-1.9.0/harbor-offline-installer-v1.9.2-rc1.tgz
# 解压
tar zxvf harbor-offline-installer-v1.9.2-rc1.tgz
# 查看
cd harbor
ls
[root@ip-172-31-23-16 harbor]# ll
total 623296
drwxr-xr-x 3 root root        20 Nov  5 05:50 common
-rw-r--r-- 1 root root      5369 Nov  5 06:07 docker-compose.yml
-rw-r--r-- 1 root root 638214056 Nov  1 03:14 harbor.v1.9.2.tar.gz
-rw-r--r-- 1 root root      5816 Nov  5 06:07 harbor.yml
-rwxr-xr-x 1 root root      5088 Nov  1 03:13 install.sh
-rw-r--r-- 1 root root     11347 Nov  1 03:13 LICENSE
-rwxr-xr-x 1 root root      1748 Nov  1 03:13 prepare
修改配置，主要修改两个文件
harbor.yml为系统配置文件，docker-compose.yml为docker相关配置文件
修改harbor.yml
vim harbor.yml
# 修改hostname
hostname: 52.83.79.244
# 修改映射端口
http:
  port: 8093
# 修改admin password（可选）
harbor_admin_password: 1qaz!QAZ
# 修改数据库相关参数
database:
  password: root
  max_idle_conns: 50
  max_open_conns: 100
# 修改数据持久化host目录
data_volume: /data/harbor
# 修改log目录
 location: /var/log/harbor
修改docker-compose.yml文件
vim docker-compose.yml
# 添加ports映射
registry:
    image: goharbor/registry-photon:v2.7.1-patch-2819-2553-v1.9.2
    container_name: registry
    restart: always
    ports:
      - 5000:5000
启动harbor
./install.sh安装之后查看
docker-compose ps
     Name                     Command                  State                 Ports
---------------------------------------------------------------------------------------------
harbor-core         /harbor/harbor_core              Up (healthy)
harbor-db           /docker-entrypoint.sh            Up (healthy)   5432/tcp
harbor-jobservice   /harbor/harbor_jobservice  ...   Up (healthy)
harbor-log          /bin/sh -c /usr/local/bin/ ...   Up (healthy)   127.0.0.1:1514-&gt;10514/tcp
harbor-portal       nginx -g daemon off;             Up (healthy)   8080/tcp
nginx               nginx -g daemon off;             Up (healthy)   0.0.0.0:8093-&gt;8080/tcp
redis               redis-server /etc/redis.conf     Up (healthy)   6379/tcp
registry            /entrypoint.sh /etc/regist ...   Restarting
registryctl         /harbor/start.sh                 Up (healthy)
登录harbor ，账号密码为harbor.yml所设置的密码
http://52.83.79.244:8093/harbor/projects
登录时候还不能直接利用docker push 到服务器，这是因为 docker1.3.2 版本开始默认 docker registry 使用的是 https，我们设置 Harbor 默认 http 方式，所以当执行用 docker login、pull、push 等命令操作非 https 的 docker regsitry 的时就会报错。解决办法：
vim /usr/lib/systemd/system/docker.service
# ExecStart 增加 --insecure-registry=52.83.79.244【配置文件中的hostname】
ExecStart=/usr/bin/dockerd $OPTIONS $DOCKER_STORAGE_OPTIONS $DOCKER_ADD_RUNTIMES --insecure-registry=52.83.79.244:8093
# 重启服务
systemctl daemon-reload
systemctl restart docker
harbor常用命令
# 需要进入harbor文件夹执行
cd /opt/harbor

docker-compose up -d               ###后台启动，如果容器不存在根据镜像自动创建
docker-compose down   -v           ###停止容器并删除容器
docker-compose start               ###启动容器，容器不存在就无法启动，不会自动创建镜像
docker-compose stop                ###停止容器
使用及配置
docker 登录到harbor
[root@ip-172-31-23-16 harbor]# docker login 52.83.79.244:8093
Username: admin
Password:
WARNING! Your password will be stored unencrypted in /root/.docker/config.json.
Configure a credential helper to remove this warning. See
https://docs.docker.com/engine/reference/commandline/login/#credentials-store

Login Succeeded


登录harbor后创建一个公共仓库，命名为wuhan
将镜像发布到harbor
# 查看需要上传的镜像
docker images
# 为镜像上tag
docker tag jenkins/jenkins:lts 52.83.79.244:8093/wuhan/jenkins:lts
# 上传到wuhan库
docker push jenkins/jenkins:lts 52.83.79.244:8093/wuhan/jenkins:lts
# 若需要上传到library库
docker push jenkins/jenkins:lts 52.83.79.244:8093/library/jenkins:lts
配置https协议# 准备工作
mkdir -p /data/harbor-cert
yum install -y openssl

------------
cd data/harbor-cert
openssl genrsa -des3 -out server.key 2048 
openssl req -new -key server.key -out server.csr 
cp server.key server.key.org openssl rsa -in server.key.org -out server.key 
openssl x509 -req -days 365 -in server.csr -signkey server.key -out server.crt 
生成证书之后，修改harbor.yaml文件具体配置如下
使用及配置
docker 登录到harbor
[root@ip-172-31-23-16 harbor]# docker login 52.83.79.244:8093
Username: admin
Password:
WARNING! Your password will be stored unencrypted in /root/.docker/config.json.
Configure a credential helper to remove this warning. See
https://docs.docker.com/engine/reference/commandline/login/#credentials-store

Login Succeeded


登录harbor后创建一个公共仓库，命名为wuhan
将镜像发布到harbor
# 查看需要上传的镜像
docker images
# 为镜像上tag
docker tag jenkins/jenkins:lts 52.83.79.244:8093/wuhan/jenkins:lts
# 上传到wuhan库
docker push jenkins/jenkins:lts 52.83.79.244:8093/wuhan/jenkins:lts
# 若需要上传到library库
docker push 52.83.79.244:8093/library/jenkins:lts
trouble shooting
docker登录harbor报错window直接修改docker设置，添加52.83.79.244:8093到docker insecure registrylinux修改方法：https://blog.csdn.net/u010397369/article/details/42422243

</div>
        </div>
      </a>

      <div>
        
          <i class="iconfont icon-riqi2"></i>&nbsp;2020-01-09&nbsp;&nbsp;
        
        
          <i class="iconfont icon-inbox"></i>
          
            <a href="/categories/%E8%BF%90%E7%BB%B4">运维</a>&nbsp;
          &nbsp;
        
        
          <i class="iconfont icon-tag"></i>
          
            <a href="/tags/https">https</a>&nbsp;
          
            <a href="/tags/%E8%AF%81%E4%B9%A6">证书</a>&nbsp;
          
            <a href="/tags/harbor">harbor</a>&nbsp;
          
            <a href="/tags/docker">docker</a>&nbsp;
          
            <a href="/tags/%E9%83%A8%E7%BD%B2">部署</a>&nbsp;
          
        
      </div>
    </div>
  </div>

  <div class="row mb-4 mx-auto">
    
    
      <div class="col-12 col-md-4 m-auto">
        <a href="/2020/01/07/K8s%E7%9B%91%E6%8E%A7%E9%83%A8%E7%BD%B2%E6%96%B9%E6%A1%88/" target="_self">
          <img src="https://www.ovh.com/blog/wp-content/uploads/2019/01/kubernetesblog02.jpg" srcset="/img/loading.gif" alt="K8s监控部署方案" class="img-fluid rounded z-depth-3 index-thumbnails">
        </a>
      </div>
    
    <div class="col-12 col-md-8 m-auto">
      <a href="/2020/01/07/K8s%E7%9B%91%E6%8E%A7%E9%83%A8%E7%BD%B2%E6%96%B9%E6%A1%88/">
        <p class="h4 index-header">K8s监控部署方案</p>
        
        
          
        
        <div class="index-excerpt" >
          <div class="index-text mb-1">架构
部署yaml文件地址 👉🏻   pythagoras
1 在k8s集群中创建namespaceapiVersion: v1
kind: Namespace
metadata: 
  name: ns-monitor
  labels:
    name: ns-monitor

kubectl apply -f namespace.yaml
2 安装node-exporter在kubernetest集群中部署node-exporter，Node-exporter用于采集kubernetes集群中各个节点的物理指标，比如：Memory、CPU等。可以直接在每个物理节点是直接安装，这里我们使用DaemonSet部署到每个节点上，使用 hostNetwork: true 和 hostPID: true 使其获得Node的物理指标信息，配置tolerations使其在master节点也启动一个pod。
node-exporter.yaml
kind: DaemonSet
apiVersion: apps/v1beta2
metadata: 
  labels:
    app: node-exporter
  name: node-exporter
  namespace: ns-monitor
spec:
  revisionHistoryLimit: 10
  selector:
    matchLabels:
      app: node-exporter
  template:
    metadata:
      labels:
        app: node-exporter
    spec:
      containers:
        - name: node-exporter
          image: prom/node-exporter:v0.16.0
          ports:
            - containerPort: 9100
              protocol: TCP
              name:    http
      hostNetwork: true
      hostPID: true
      tolerations:
        - effect: NoSchedule
          operator: Exists

---
kind: Service
apiVersion: v1
metadata:
  labels:
    app: node-exporter
  name: node-exporter-service
  namespace: ns-monitor
spec:
  ports:
    - name:    http
      port: 9100
      nodePort: 31672
      protocol: TCP
  type: NodePort
  selector:
    app: node-exporter
kubectl apply -f node-exporter.yaml
*检查是否执行成功(对应pod及svc) 👉🏻 **
➜  ~ kubectl get pod -n ns-monitor
NAME                          READY   STATUS    RESTARTS   AGE
grafana-547699f75-lxljq       1/1     Running   0          3h37m
node-exporter-75nmc           0/1     Pending   0          20h
node-exporter-t29kx           1/1     Running   0          20h
node-exporter-z6s7x           1/1     Running   0          20h
prometheus-7d7654554d-f5fvf   1/1     Running   0          3h45m
➜  ~ kubectl get svc -n ns-monitor
NAME                    TYPE       CLUSTER-IP     EXTERNAL-IP   PORT(S)          AGE
grafana-service         NodePort   10.1.242.56    &lt;none&gt;        3000:31026/TCP   3h38m
node-exporter-service   NodePort   10.1.130.7     &lt;none&gt;        9100:31672/TCP   20h
prometheus-service      NodePort   10.1.133.130   &lt;none&gt;        9090:30753/TCP   3h45m

3 部署Prometheus podprometheus.yaml 中包含rbac认证、ConfigMap等
kubectl apply -f prometheus.yaml 
检查是否执行成功(对应pod及svc)* 👉🏻 
➜  ~ kubectl get pod -n ns-monitor
NAME                          READY   STATUS    RESTARTS   AGE
grafana-547699f75-lxljq       1/1     Running   0          3h37m
node-exporter-75nmc           0/1     Pending   0          20h
node-exporter-t29kx           1/1     Running   0          20h
node-exporter-z6s7x           1/1     Running   0          20h
prometheus-7d7654554d-f5fvf   1/1     Running   0          3h45m
➜  ~ kubectl get svc -n ns-monitor
NAME                    TYPE       CLUSTER-IP     EXTERNAL-IP   PORT(S)          AGE
grafana-service         NodePort   10.1.242.56    &lt;none&gt;        3000:31026/TCP   3h38m
node-exporter-service   NodePort   10.1.130.7     &lt;none&gt;        9100:31672/TCP   20h
prometheus-service      NodePort   10.1.133.130   &lt;none&gt;        9090:30753/TCP   3h45m

4 在k8s中部署grafanakubectl apply -f grafana.yaml
检查是否执行成功(对应pod及svc) 👉🏻 
➜  ~ kubectl get pod -n ns-monitor
NAME                          READY   STATUS    RESTARTS   AGE
grafana-547699f75-lxljq       1/1     Running   0          3h37m
node-exporter-75nmc           0/1     Pending   0          20h
node-exporter-t29kx           1/1     Running   0          20h
node-exporter-z6s7x           1/1     Running   0          20h
prometheus-7d7654554d-f5fvf   1/1     Running   0          3h45m
➜  ~ kubectl get svc -n ns-monitor
NAME                    TYPE       CLUSTER-IP     EXTERNAL-IP   PORT(S)          AGE
grafana-service         NodePort   10.1.242.56    &lt;none&gt;        3000:31026/TCP   3h38m
node-exporter-service   NodePort   10.1.130.7     &lt;none&gt;        9100:31672/TCP   20h
prometheus-service      NodePort   10.1.133.130   &lt;none&gt;        9090:30753/TCP   3h45m
5 配置grafana数据源把prometheus配置成数据源 ：http://prometheus-service.ns-monitor:9090

6 倒入dashboard把 kubernetes的Dashboard的模板导入进来，直接把JSON格式内容复制进来。

效果图
Ref
使用Prometheus监控kubernetes集群

k8s安装Prometheus+Grafana

github-kubernetes-promethues

github-giantswarm-promethues


</div>
        </div>
      </a>

      <div>
        
          <i class="iconfont icon-riqi2"></i>&nbsp;2020-01-07&nbsp;&nbsp;
        
        
          <i class="iconfont icon-inbox"></i>
          
            <a href="/categories/kubernetes">kubernetes</a>&nbsp;
          &nbsp;
        
        
          <i class="iconfont icon-tag"></i>
          
            <a href="/tags/kubernetes">kubernetes</a>&nbsp;
          
            <a href="/tags/grafana">grafana</a>&nbsp;
          
            <a href="/tags/prometheus">prometheus</a>&nbsp;
          
            <a href="/tags/%E7%9B%91%E6%8E%A7">监控</a>&nbsp;
          
            <a href="/tags/%E9%83%A8%E7%BD%B2">部署</a>&nbsp;
          
        
      </div>
    </div>
  </div>

  <div class="row mb-4 mx-auto">
    
    
      <div class="col-12 col-md-4 m-auto">
        <a href="/2020/01/07/gitlab%E5%BC%80%E5%90%AFhttps/" target="_self">
          <img src="https://i.loli.net/2020/01/09/THWYZKhmjqslku4.png" srcset="/img/loading.gif" alt="Gitlab开启Https" class="img-fluid rounded z-depth-3 index-thumbnails">
        </a>
      </div>
    
    <div class="col-12 col-md-8 m-auto">
      <a href="/2020/01/07/gitlab%E5%BC%80%E5%90%AFhttps/">
        <p class="h4 index-header">Gitlab开启Https</p>
        
        
          
        
        <div class="index-excerpt" >
          <div class="index-text mb-1">Gitlab开启Https建立认证目录mkdir -p /etc/gitlab/ssl
chmod 700 /etc/gitlab/ssl
建立证书# step 1 创建private key （记住输入的密码（Pass phrase））
openssl genrsa -des3 -out /etc/gitlab/ssl/server.key 2048

# step 2 生成 Certificate Request
openssl req -new -key /etc/gitlab/ssl/gitlab.domain.com.key -out /etc/gitlab/ssl/server.csr

 Enter Country Name CN Enter State or Province Full Name HB Enter City Name WuHan Enter Organization Name Enter Company Name EV-IV Enter Organizational Unit Name Enter server hostname i.e. URL gitlab.domain.com Enter Admin Email Address Skip Challenge Password (Hit Enter) Skip Optional Company Name (Hit Enter)

#在加载SSL支持的Nginx并使用上述私钥时要除去刚才设置的口令： 
#step3 备份csr文件及去除命令，直接覆盖了server.key了
openssl rsa -inserver.key.org -out server.key
#step 4最后标记证书使用上述私钥和CSR：（把csr标记后转换成了crt nginx要用key和crt文件）
openssl x509 -req -days 365 -in server.csr -signkey server.key -out server.crt
修改gitlab配置vim /etc/gitlab/gitlab.rb

external_url &#39;https://161.189.27.8:8090/&#39;

nginx[&#39;redirect_http_to_https&#39;]= true
nginx[&#39;ssl_client_certificate&#39;] = &quot;/etc/gitlab/ssl/server.crt&quot;
nginx[&#39;ssl_certificate&#39;]= &quot;/etc/gitlab/ssl/server.crt&quot;
nginx[&#39;ssl_certificate_key&#39;]= &quot;/etc/gitlab/ssl/server.key&quot;
重启gitlabgitlab-ctl reconfigure
gitlab-ctl restart
最后通过访问https地址进行访问测试
相关问题Q1 由于ssl证书为自签证书 git clone报错
git clone https://161.189.27.8:8090/dqdev/pythogoras.git
Cloning into &#39;pythogoras&#39;...
fatal: unable to access &#39;https://161.189.27.8:8090/dqdev/pythogoras.git/&#39;: SSL certificate problem: self signed certificate
关闭git ssl验证
git config --global http.sslVerify false 关闭
git config --global http.sslVerify true  开启
</div>
        </div>
      </a>

      <div>
        
          <i class="iconfont icon-riqi2"></i>&nbsp;2020-01-07&nbsp;&nbsp;
        
        
          <i class="iconfont icon-inbox"></i>
          
            <a href="/categories/%E8%BF%90%E7%BB%B4">运维</a>&nbsp;
          &nbsp;
        
        
          <i class="iconfont icon-tag"></i>
          
            <a href="/tags/gitlab">gitlab</a>&nbsp;
          
            <a href="/tags/ssl">ssl</a>&nbsp;
          
            <a href="/tags/https">https</a>&nbsp;
          
            <a href="/tags/%E8%AF%81%E4%B9%A6">证书</a>&nbsp;
          
        
      </div>
    </div>
  </div>





              </div>
            </div>
          </div>
        </div>
      </div>
    
  </main>

  
    <a class="z-depth-1" id="scroll-top-button" href="#" role="button">
      <i class="fa fa-chevron-up scroll-top-arrow" aria-hidden="true"></i>
    </a>
  

  
    <div class="modal fade" id="modalSearch" tabindex="-1" role="dialog" aria-labelledby="ModalLabel"
     aria-hidden="true">
  <div class="modal-dialog modal-dialog-scrollable modal-lg" role="document">
    <div class="modal-content">
      <div class="modal-header text-center">
        <h4 class="modal-title w-100 font-weight-bold">搜索</h4>
        <button type="button" id="local-search-close" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body mx-3">
        <div class="md-form mb-5">
          <input type="text" id="local-search-input" class="form-control validate">
          <label data-error="x" data-success="v"
                 for="local-search-input">关键词</label>
        </div>
        <div class="list-group" id="local-search-result"></div>
      </div>
    </div>
  </div>
</div>
  

  <footer class="mt-5">
  <div class="text-center py-3">
    <a href="https://hexo.io" target="_blank" rel="nofollow noopener"><b>Hexo</b></a>
    <i class="iconfont icon-love"></i>
    <a href="https://github.com/fluid-dev/hexo-theme-fluid" target="_blank" rel="nofollow noopener"> <b>Fluid</b></a>
    <br>

    
  
    <!-- 不蒜子统计PV -->
    
    &nbsp;<span id="busuanzi_container_site_pv">总访问量 
          <span id="busuanzi_value_site_pv"></span> 次</span>&nbsp;
  
  
    <!-- 不蒜子统计UV -->
    
    &nbsp;<span id="busuanzi_container_site_uv">总访客数 
            <span id="busuanzi_value_site_uv"></span> 人</span>&nbsp;
  
  <br>



    


    <!-- cnzz Analytics icon -->
    

  </div>
</footer>

<!-- SCRIPTS -->
<script src="https://cdn.staticfile.org/jquery/3.4.1/jquery.min.js" ></script>
<script src="https://cdn.staticfile.org/popper.js/1.15.0/umd/popper.min.js" ></script>
<script src="https://cdn.staticfile.org/twitter-bootstrap/4.3.1/js/bootstrap.min.js" ></script>
<script src="https://cdn.staticfile.org/mdbootstrap/4.8.9/js/mdb.min.js" ></script>
<script src="/js/main.js" ></script>


  <script src="/js/lazyload.js" ></script>





  <script src="https://cdn.staticfile.org/smooth-scroll/16.1.0/smooth-scroll.min.js" ></script>



  <script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js" ></script>


<!-- Plugins -->


  

  

  

  

  <!-- cnzz Analytics -->
  



  <script src="https://cdn.staticfile.org/prettify/r298/prettify.min.js" ></script>
  <script>
    $(document).ready(function () {
      $('pre').addClass('prettyprint  linenums');
      prettyPrint();
    })
  </script>



  <script src="https://cdn.staticfile.org/typed.js/2.0.10/typed.min.js" ></script>
  <script>
    var typed = new Typed('#subtitle', {
      strings: [
        '  ',
        "Hello World&nbsp;",
      ],
      cursorChar: "_",
      typeSpeed: 70,
      loop: false,
    });
    typed.stop();
    $(document).ready(function () {
      $(".typed-cursor").addClass("h2");
      typed.start();
    });
  </script>



  <script src="https://cdn.staticfile.org/anchor-js/4.2.0/anchor.min.js" ></script>
  <script>
    anchors.options = {
      placement: "right",
      visible: "false",
      
    };
    var el = "h1,h2,h3,h4,h5,h6".split(",");
    var res = [];
    for (item of el) {
      res.push(".markdown-body > " + item)
    }
    anchors.add(res.join(", "))
  </script>



  <script src="/js/local-search.js" ></script>
  <script>
    var path = "/local-search.xml";
    var inputArea = document.querySelector("#local-search-input");
    inputArea.onclick = function () {
      getSearchFile(path);
      this.onclick = null
    }
  </script>



  <script src="https://cdn.staticfile.org/fancybox/3.5.7/jquery.fancybox.min.js" ></script>
  <script>
    $("#post img:not(.no-zoom img, img[no-zoom])").each(
      function () {
        var element = document.createElement("a");
        $(element).attr("data-fancybox", "images");
        $(element).attr("href", $(this).attr("src"));
        $(this).wrap(element);
      }
    );
  </script>











</body>
</html>
