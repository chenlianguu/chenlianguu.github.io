<?xml version="1.0" encoding="utf-8"?>
<search>
  
  
  
  <entry>
    <title>Docker部署伪分布式大数据环境</title>
    <link href="/2020/01/09/Docker%E9%83%A8%E7%BD%B2%E4%BC%AA%E5%88%86%E5%B8%83%E5%BC%8F%E5%A4%A7%E6%95%B0%E6%8D%AE%E7%8E%AF%E5%A2%83/"/>
    <url>/2020/01/09/Docker%E9%83%A8%E7%BD%B2%E4%BC%AA%E5%88%86%E5%B8%83%E5%BC%8F%E5%A4%A7%E6%95%B0%E6%8D%AE%E7%8E%AF%E5%A2%83/</url>
    
    <content type="html"><![CDATA[<h2 id="思路"><a href="#思路" class="headerlink" title="思路"></a>思路</h2><p>通过docker搭建大数据环境  </p><ul><li>开箱即用，不常驻后台，需要的时候启动集群即可，不用的时候关闭集群释放机器资源</li><li>避免了直接安装端口占用问题，大数据平台所需端口较多</li><li>spark资源docker化，便于后期k8s进行资源管理调度</li></ul><p>上述好处主要是基于测试环境下，基于生产环境的大数据平台化要考虑的点很多，例如后期扩容、运维、安全等因素，大数据平台整个是否docker化后期有待考证。</p><h2 id="镜像制作方案"><a href="#镜像制作方案" class="headerlink" title="镜像制作方案"></a>镜像制作方案</h2><p>使用Docker来搭建hadoop,spark及mysql的集群，首先使用Dockerfile制作镜像，把相关的软件拷贝到约定好的目录 下，把配置文件在外面先配置好，再拷贝移动到hadoop,spark的配置目录，为了能使得mysql能从其它节点被访问到，要配置mysql的访问权限。</p><h2 id="整体架构"><a href="#整体架构" class="headerlink" title="整体架构"></a>整体架构</h2><p>一共3个节点，即启动3个容器。hadoop-master,hadoop-node1,hadoop-node2这三个容器里面安装hadoop和spark集群。<br><img src="https://i.loli.net/2020/01/09/HIAsFMrPekj4fZw.png" srcset="/img/loading.gif" alt="architect.png"></p><h2 id="集群部署"><a href="#集群部署" class="headerlink" title="集群部署"></a>集群部署</h2><h3 id="集群网络规划及子网配置"><a href="#集群网络规划及子网配置" class="headerlink" title="集群网络规划及子网配置"></a>集群网络规划及子网配置</h3><p>既然是做集群，网络的规划是少不了的,至于网络，可以通过Docker中的DockerNetworking的支持配置。首先设置网络，docker中设置 子网可以通过docker network create 方法，这里我们通过命令设置如下的子网。–subnet指定子网络的网段，并为这个子网命名一个名字叫spark</p><pre><code class="shell"># 创建子网docker network create --subnet=172.16.0.0/16 spark# 查看网络docker network lsNETWORK ID          NAME                       DRIVER              SCOPEfab2dd51d1cf        spark                      bridge              local</code></pre><p> 接下来就在我们创建的子网落spark中规划集群中每个容器的ip地址。网络ip分配如下:</p><p>hadoop-master 172.16.0.2</p><p>hadoop-node1 172.16.0.3</p><p>hadoop-node2 172.16.0.4</p><h3 id="软件版本"><a href="#软件版本" class="headerlink" title="软件版本"></a>软件版本</h3><p>网络规划好了，首先Spark我们使用最新的2.4.4版本，Hadoop采用比较稳定的hadoop-2.7.3版本，scala采用scala-2.11.8，JDK采用jdk-8u101-linux-x64。</p><h3 id="SSH无密钥登录规则配置"><a href="#SSH无密钥登录规则配置" class="headerlink" title="SSH无密钥登录规则配置"></a>SSH无密钥登录规则配置</h3><p>注意这里不使用ssh-keygen -t rsa -P ‘’这种方式生成id_rsa.pub，然后集群节点互拷贝id_rsa.pub到authorized_keys文件这种方式，而 是通过在.ssh目录下配置ssh_conf文件的方式，ssh_conf中可以配置SSH的通信规则，例如以正则表达式的方式指定hostname为XXX的 机器之间实现互联互通，而不进行额外的密钥验证。为了编写这个正则表达式，我们5个节点的hostname都以hadoop-*的方式作为开 头，这就是采用这种命名规则的原因。下面来看下ssh_conf配置的内容:</p><pre><code class="shell">Host localhost    StrictHostKeyChecking noHost 0.0.0.0     StrictHostKeyChecking noHost hadoop-*     StrictHostKeyChecking no</code></pre><p>注意上面的最后一行，Host hadoop-* 指定了它的严格的Host验证StrictHostKeyChecking 为no，这样既可以是这5个hostname以 hadoop-*开头的容器之间实现互联互通，而不需要二外的验证。</p><h3 id="构建镜像"><a href="#构建镜像" class="headerlink" title="构建镜像"></a>构建镜像</h3><p>Dockerfile编写完成，接下来写一个build.sh脚本，内容如下:</p><pre><code class="shell"> echo build hadoop images docker build -t=&quot;spark&quot; . </code></pre><p>表示构建一个名叫spark的镜像，.表示Dockerfile的路径，因为在当前路径下，所有用.,若在其他地方则用绝对路径指定Dockerfile的路径 即可。</p><p>运行sh build.sh，就会开始制作镜像了。</p><h2 id="集群运行"><a href="#集群运行" class="headerlink" title="集群运行"></a>集群运行</h2><h3 id="启动容器-start-container-sh"><a href="#启动容器-start-container-sh" class="headerlink" title="启动容器 start_container.sh"></a>启动容器 start_container.sh</h3><p>使用这个镜像可完成容器的启动，因为使用了基于DockerNetworking的网络机制，因此可以在启动容器的时候为容器在子网172.16.0.0/16 spark中分贝172.16.0.1 172.16.0.255以外的IP地址，容器内部容器的通信是基于hostname，因此 需要指定hostname，为了方便容器的管理，需要为启动的每个容器指定一个名字。为了方便外网访问，需要通过-p命令指定容器到宿主机的端口映射。还要为每个容器增加host列表。</p><pre><code class="shell"># hadoop-masterdocker run -itd --restart=always \    --net spark \    --ip 172.16.0.2 \    --privileged \    -p 18032:8032 \    -p 28080:18080 \    -p 29888:19888 \    -p 17077:7077 \    -p 51070:50070 \    -p 18888:8888 \    -p 19000:9000 \    -p 11100:11000 \    -p 51030:50030 \    -p 18050:8050 \    -p 18081:8081 \    -p 18900:8900 \    --name hadoop-master \    --hostname hadoop-master \    --add-host hadoop-node1:172.16.0.3 \    --add-host hadoop-node2:172.16.0.4 \    --add-host hadoop-mysql:172.16.0.6 \    spark /usr/sbin/init# hadoop-node1docker run -itd --restart=always \    --net spark \    --ip 172.16.0.3 \    --privileged \    -p 18042:8042 \    -p 51010:50010 \    -p 51020:50020 \    --name hadoop-node1 \    --hostname hadoop-node1 \    --add-host hadoop-master:172.16.0.2 \    --add-host hadoop-node2:172.16.0.4 \    spark /usr/sbin/init# hadoop-node2docker run -itd --restart=always \    --net spark \    --ip 172.16.0.4 \    --privileged \    -p 18043:8042 \    -p 51011:50011 \    -p 51021:50021 \    --name hadoop-node2 \    --hostname hadoop-node2 \    --add-host hadoop-master:172.16.0.2 \    --add-host hadoop-node1:172.16.0.3 \    spark /usr/sbin/init</code></pre><h3 id="关闭集群-stop-container-sh"><a href="#关闭集群-stop-container-sh" class="headerlink" title="关闭集群 stop_container.sh"></a>关闭集群 stop_container.sh</h3><pre><code class="shell">echo stop containersdocker stop hadoop-masterdocker stop hadoop-node1docker stop hadoop-node2echo remove containersdocker rm hadoop-masterdocker rm hadoop-node1docker rm hadoop-node2echo rm containersdocker ps</code></pre><h3 id="重启集群-restart-container-sh"><a href="#重启集群-restart-container-sh" class="headerlink" title="重启集群 restart_container.sh"></a>重启集群 restart_container.sh</h3><pre><code class="shell">echo stop containersdocker stop hadoop-masterdocker stop hadoop-node1docker stop hadoop-node2echo restart containersdocker start hadoop-masterdocker start hadoop-node1docker start hadoop-node2echo start sshddocker exec -it hadoop-master systemctl start sshddocker exec -it hadoop-node1 systemctl start sshddocker exec -it hadoop-node2 systemctl start sshddocker exec -it hadoop-master ~/restart-hadoop.shecho  containers starteddocker ps</code></pre><h2 id="Trouble-Shooting"><a href="#Trouble-Shooting" class="headerlink" title="Trouble Shooting"></a>Trouble Shooting</h2><ul><li><p>docker里面执行systemctl报错</p><p>解决方案：启动的时候用/usr/sbin/init</p></li><li><p>docker登录harbor报错<br>window直接修改docker设置，添加52.83.79.244:8093到docker insecure registry<br>linux修改方法：<a href="https://blog.csdn.net/u010397369/article/details/42422243" target="_blank" rel="noopener">https://blog.csdn.net/u010397369/article/details/42422243</a>  </p></li></ul><h2 id="Demo"><a href="#Demo" class="headerlink" title="Demo"></a>Demo</h2><p>进入hadoop-master容器内部，执行spark-shell</p><pre><code class="shell">root@node-2 docker-spark]# docker exec -it hadoop-master /bin/bash[root@hadoop-master ~]# sparkspark-class   spark-shell   spark-sql     spark-submit  sparkR[root@hadoop-master ~]# spark-shell19/12/03 04:51:25 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicableSetting default log level to &quot;WARN&quot;.To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).19/12/03 04:51:43 WARN util.Utils: spark.executor.instances less than spark.dynamicAllocation.minExecutors is invalid, ignoring its setting, please update your configs.Spark context Web UI available at http://hadoop-master:4040Spark context available as &#39;sc&#39; (master = spark://hadoop-master:7077, app id = app-20191203045141-0000).Spark session available as &#39;spark&#39;.Welcome to      ____              __     / __/__  ___ _____/ /__    _\ \/ _ \/ _ `/ __/  &#39;_/   /___/ .__/\_,_/_/ /_/\_\   version 2.4.4      /_/Using Scala version 2.11.12 (Java HotSpot(TM) 64-Bit Server VM, Java 1.8.0_101)Type in expressions to have them evaluated.Type :help for more information.scala&gt;</code></pre><h2 id="本地部署"><a href="#本地部署" class="headerlink" title="本地部署"></a>本地部署</h2><ul><li><p>想要在自己的笔记本环境使用</p><p>首先笔记本环境下需要有docker环境</p><ul><li>拉取gitlab上面的项目：git clone <a href="mailto:git@161.189.27.8">git@161.189.27.8</a>:chenliang/docker-spark.git</li><li>拉去harbor上面的镜像：docker pull 52.83.79.244:8093/wuhan/spark:v1（也可以自己构建镜像，Dockerfile文件在gitlab项目里边）<br>  前提：机器docker环境登录harbor，账号密码：admin 1qaz!QAZ<br>docker login 52.83.79.244:8093<br>登录报错：Error response from daemon: Get <a href="https://52.83.79.244:8093/v2/" target="_blank" rel="noopener">https://52.83.79.244:8093/v2/</a>: http: server gave HTTP response to HTTPS client<br>解决：参见trouble shooting</li><li>使用相关脚本执行启动、停止、重启集群</li></ul></li></ul><ul><li><p>如何自己的spark程序如何在docker环境下执行  </p><p>启动spark的集群之后，使用docker cp等命令将打好的jar包打进容器内，使用spark脚本执行</p></li></ul>]]></content>
    
    
    <categories>
      
      <category>运维</category>
      
    </categories>
    
    
    <tags>
      
      <tag>docker</tag>
      
      <tag>环境</tag>
      
      <tag>大数据</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Docker部署Nextcloud</title>
    <link href="/2020/01/09/Docker%E9%83%A8%E7%BD%B2Nextcloud/"/>
    <url>/2020/01/09/Docker%E9%83%A8%E7%BD%B2Nextcloud/</url>
    
    <content type="html"><![CDATA[<h2 id="准备工作"><a href="#准备工作" class="headerlink" title="准备工作"></a>准备工作</h2><h3 id="docker的安装及配置"><a href="#docker的安装及配置" class="headerlink" title="docker的安装及配置"></a>docker的安装及配置</h3><pre><code class="shell"># 通过yum安装yum install -y docker-ce# 启动docker并设置开机启动systemctl start dockersystemctl enable docker# aws ec2 linux2另外一种安装方式sudo amazon-linux-extras install dockersudo service docker start</code></pre><p>由于docker镜像源默认是在国外，拉取镜像速度非常慢，修改daemon配置文件/etc/docker/daemon.json来使用加速器</p><pre><code class="shell">mkdir -p /etc/dockertouch /etc/docker/daemon.jsonvim /etc/docker/daemon.json{  &quot;registry-mirrors&quot;: [&quot;https://b3sst9pc.mirror.aliyuncs.com&quot;]}systemctl daemon-reloadsystemctl restart docker</code></pre><h3 id="docker-compose安装"><a href="#docker-compose安装" class="headerlink" title="docker-compose安装"></a>docker-compose安装</h3><p>Docker Compose是 docker 提供的一个命令行工具，用来定义和运行由多个容器组成的应用。使用 compose，我们可以通过 YAML 文件声明式的定义应用程序的各个服务，并由单个命令完成应用的创建和启动。</p><ul><li><p>docker-compose命令安装</p><pre><code class="shell"># 安装pipyum -y install epel-releaseyum -y install python-pip# 确认版本pip --version# 更新pippip install --upgrade pip# 安装docker-composepip install docker-compose # 查看版本docker-compose version</code></pre></li></ul><h2 id="nextcloud的部署"><a href="#nextcloud的部署" class="headerlink" title="nextcloud的部署"></a>nextcloud的部署</h2><p>nextcloud通过docker-compose命令进行构建，创建 docker-compose.yml文件</p><pre><code class="shell"># 创建docker-compose.yml文件touch docker-compose.yml# 粘贴以下内容version: &#39;2&#39;services:  db:    image: mariadb    restart: always    volumes:      - /data/mariadb:/var/lib/mysql    environment:      - MYSQL_ROOT_PASSWORD=root      - MYSQL_PASSWORD=nextcloud      - MYSQL_DATABASE=nextcloud      - MYSQL_USER=nextcloud  app:    image: nextcloud    restart: always    ports:      - 8091:80    links:      - db    volumes:      - /data/nextcloud/data:/var/www/html/data          - /data/nextcloud/themes:/var/www/html/themes      - /data/nextcloud/apps:/var/www/html/custom_apps</code></pre><p>docker-compose.yml文件说明</p><p>通过启动两个service服务mariadb及nextcloud服务，并通过link连接到一起，其中将/var/www/html/data、/var/www/html/themes、/var/www/html/custom_apps映射到linux服务器指定目录实现数据持久化，这样下次docker重启的时候数据不会发生丢失。</p><p>nextcloud实现预览编辑office文件需要插件onlyoffice支持，通过docker创建onlyoffice服务器，并启动nextcloud配置onlyoffice</p><pre><code class="shell">docker run -it -d -p 8061:80 onlyoffice/documentserver  -v /data/onlyoffice/logs:/var/log/onlyoffice /data/onlyoffice/data:/var/www/onlyoffice/Data /data/onlyoffice/lib:/var/lib/onlyoffice /data/onlyoffice/db:/var/lib/postgresql</code></pre><p>启动nextcloud、停止nextcloud、查看nextcloud启动状态</p><pre><code class="shell"># 启动nextclouddocker-compose up -d# 查看nextcloud状态docker-compose ps# 停止nextclouddocker-compose stop</code></pre><h2 id="nextcloud的数据迁移"><a href="#nextcloud的数据迁移" class="headerlink" title="nextcloud的数据迁移"></a>nextcloud的数据迁移</h2><p>当需要nextcloud迁移到另外一台服务的时候，需要将nextcloud持久化的数据通过scp或者其他方式复制到另外一台机器，将原来的机器mariadb的nextcloud数据库进行导出，在新的机器上面导入数据库数据。复制YAML文件到新的机器，通过docker-compose进行启动，进入容器内部修改持久化数据的权限及修改nextcloud配置文件，最后重启容器。</p><pre><code class="shell"># 复制持久化数据到新的机器上面scp -R /data/nextcloud root@192.168.12.1:/data# 导出原来机器的上面的mariadb数据docker exec -it  nextcloud_db_1【docker容器名称/ID】 mysqldump -uroot -proot【数据库密码】 nextcloud【数据库名称】 &gt; /opt/sql_bak/nextcloud.sql【导出表格路径】# 将sql文件复制到新的机器上面scp  /opt/sql_bak/nextcloud.sql root@192.168.12.1:/opt/sql_bak# 在新的机器上面执行该sql文件(需要先启动docker容器)docker cp /opt/sql_bak/nextcloud.sql 【容器名】:/root/docker exec -it 【容器名/ID】shmysql -uroot -p nextcloud【数据库名】 &lt; /root/nextcloud.sql# 通过docker-compose启动镜像，修改权限 docker exec -it -u root nextcloud_app_1【容器id/容器名】 /bin/bash root@bafc02ce112a:/var/www/html# chown -R www-data:root /var/www/html/ root@bafc02ce112a:exit# 修改nextcloud配置文件vim /data/nextcloud/config/config.php# 修改ip&#39;trusted_domains&#39; =&gt;  array (    0 =&gt; &#39;161.189.27.8:8091&#39;,  ),  &#39;datadirectory&#39; =&gt; &#39;/var/www/html/data&#39;,  &#39;dbtype&#39; =&gt; &#39;mysql&#39;,  &#39;version&#39; =&gt; &#39;16.0.4.1&#39;,  &#39;overwrite.cli.url&#39; =&gt; &#39;http://161.189.27.8:8091&#39;,# 重启docker-compose restart</code></pre><h2 id="trouble-shooting"><a href="#trouble-shooting" class="headerlink" title="trouble shooting"></a>trouble shooting</h2><ul><li><p>安装docker-compose命令执行pip install docker-compose的时候报以下错误</p><pre><code>ERROR: Cannot uninstall &#39;requests&#39;. It is a distutils installed project and thus we cannot accurately determine which files belong to it which would lead to only a partial uninstall.</code></pre><p>解决版本，强制安装requests包</p><pre><code class="shell"> pip install --ignore-installed requests</code></pre><p>再重新执行</p><pre><code class="shell">pip install docker-compose</code></pre></li><li><p>docker-compose报错：No module named ssl_match_hostname</p><pre><code>File &quot;/usr/local/lib/python2.7/dist-packages/docker/transport/ssladapter.py&quot;, line 23, in &lt;module&gt;from backports.ssl_match_hostname import match_hostnameImportError: No module named ssl_match_hostname</code></pre><p>原因：</p><p><strong>/usr/local/lib/python2.7/distpackages/docker/transport/ssladapter.py **<br>在包路径下找不到 **backports包里的ssl_match_hostname</strong>模块</p><p>解决办法</p><pre><code class="shell">#进入backports模块路径cd /usr/lib/python2.7/site-packages#复制整个包到transport包路径下cp -r backports /usr/lib/python2.7/site-packages/docker/transport</code></pre></li></ul>]]></content>
    
    
    <categories>
      
      <category>运维</category>
      
    </categories>
    
    
    <tags>
      
      <tag>docker</tag>
      
      <tag>nextcloud</tag>
      
      <tag>网盘</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Harbor部署</title>
    <link href="/2020/01/09/Harbor%E9%83%A8%E7%BD%B2/"/>
    <url>/2020/01/09/Harbor%E9%83%A8%E7%BD%B2/</url>
    
    <content type="html"><![CDATA[<h2 id="harbor搭建"><a href="#harbor搭建" class="headerlink" title="harbor搭建"></a>harbor搭建</h2><p>官方提供两种方式安装harbor，离线及在线方式。本文档描述离线方式进行安装</p><p>查看docker-compose版本，若版本低进行升级安装，</p><p>下载官方安装包</p><pre><code class="shell">cd /optwget https://storage.googleapis.com/harbor-releases/release-1.9.0/harbor-offline-installer-v1.9.2-rc1.tgz# 解压tar zxvf harbor-offline-installer-v1.9.2-rc1.tgz# 查看cd harborls[root@ip-172-31-23-16 harbor]# lltotal 623296drwxr-xr-x 3 root root        20 Nov  5 05:50 common-rw-r--r-- 1 root root      5369 Nov  5 06:07 docker-compose.yml-rw-r--r-- 1 root root 638214056 Nov  1 03:14 harbor.v1.9.2.tar.gz-rw-r--r-- 1 root root      5816 Nov  5 06:07 harbor.yml-rwxr-xr-x 1 root root      5088 Nov  1 03:13 install.sh-rw-r--r-- 1 root root     11347 Nov  1 03:13 LICENSE-rwxr-xr-x 1 root root      1748 Nov  1 03:13 prepare</code></pre><p>修改配置，主要修改两个文件</p><p>harbor.yml为系统配置文件，docker-compose.yml为docker相关配置文件</p><p>修改harbor.yml</p><pre><code class="shell">vim harbor.yml# 修改hostnamehostname: 52.83.79.244# 修改映射端口http:  port: 8093# 修改admin password（可选）harbor_admin_password: 1qaz!QAZ# 修改数据库相关参数database:  password: root  max_idle_conns: 50  max_open_conns: 100# 修改数据持久化host目录data_volume: /data/harbor# 修改log目录 location: /var/log/harbor</code></pre><p>修改docker-compose.yml文件</p><pre><code class="yaml">vim docker-compose.yml# 添加ports映射registry:    image: goharbor/registry-photon:v2.7.1-patch-2819-2553-v1.9.2    container_name: registry    restart: always    ports:      - 5000:5000</code></pre><p>启动harbor</p><pre><code>./install.sh</code></pre><p>安装之后查看</p><pre><code class="shell">docker-compose ps     Name                     Command                  State                 Ports---------------------------------------------------------------------------------------------harbor-core         /harbor/harbor_core              Up (healthy)harbor-db           /docker-entrypoint.sh            Up (healthy)   5432/tcpharbor-jobservice   /harbor/harbor_jobservice  ...   Up (healthy)harbor-log          /bin/sh -c /usr/local/bin/ ...   Up (healthy)   127.0.0.1:1514-&gt;10514/tcpharbor-portal       nginx -g daemon off;             Up (healthy)   8080/tcpnginx               nginx -g daemon off;             Up (healthy)   0.0.0.0:8093-&gt;8080/tcpredis               redis-server /etc/redis.conf     Up (healthy)   6379/tcpregistry            /entrypoint.sh /etc/regist ...   Restartingregistryctl         /harbor/start.sh                 Up (healthy)</code></pre><p>登录harbor ，账号密码为harbor.yml所设置的密码</p><p><a href="http://52.83.79.244:8093/harbor/projects" target="_blank" rel="noopener">http://52.83.79.244:8093/harbor/projects</a></p><p>登录时候还不能直接利用docker push 到服务器，这是因为 docker1.3.2 版本开始默认 docker registry 使用的是 https，我们设置 Harbor 默认 http 方式，所以当执行用 docker login、pull、push 等命令操作非 https 的 docker regsitry 的时就会报错。解决办法：</p><pre><code class="shell">vim /usr/lib/systemd/system/docker.service# ExecStart 增加 --insecure-registry=52.83.79.244【配置文件中的hostname】ExecStart=/usr/bin/dockerd $OPTIONS $DOCKER_STORAGE_OPTIONS $DOCKER_ADD_RUNTIMES --insecure-registry=52.83.79.244:8093# 重启服务systemctl daemon-reloadsystemctl restart docker</code></pre><p>harbor常用命令</p><pre><code class="shell"># 需要进入harbor文件夹执行cd /opt/harbordocker-compose up -d               ###后台启动，如果容器不存在根据镜像自动创建docker-compose down   -v           ###停止容器并删除容器docker-compose start               ###启动容器，容器不存在就无法启动，不会自动创建镜像docker-compose stop                ###停止容器</code></pre><h2 id="使用及配置"><a href="#使用及配置" class="headerlink" title="使用及配置"></a>使用及配置</h2><ul><li><p>docker 登录到harbor</p><pre><code class="shell">[root@ip-172-31-23-16 harbor]# docker login 52.83.79.244:8093Username: adminPassword:WARNING! Your password will be stored unencrypted in /root/.docker/config.json.Configure a credential helper to remove this warning. Seehttps://docs.docker.com/engine/reference/commandline/login/#credentials-storeLogin Succeeded</code></pre></li></ul><p>登录harbor后创建一个公共仓库，命名为wuhan</p><p>将镜像发布到harbor</p><pre><code class="shell"># 查看需要上传的镜像docker images# 为镜像上tagdocker tag jenkins/jenkins:lts 52.83.79.244:8093/wuhan/jenkins:lts# 上传到wuhan库docker push jenkins/jenkins:lts 52.83.79.244:8093/wuhan/jenkins:lts# 若需要上传到library库docker push jenkins/jenkins:lts 52.83.79.244:8093/library/jenkins:lts</code></pre><h2 id="配置https协议"><a href="#配置https协议" class="headerlink" title="配置https协议"></a>配置https协议</h2><pre><code class="shell"># 准备工作mkdir -p /data/harbor-certyum install -y openssl------------cd data/harbor-certopenssl genrsa -des3 -out server.key 2048 openssl req -new -key server.key -out server.csr cp server.key server.key.org openssl rsa -in server.key.org -out server.key openssl x509 -req -days 365 -in server.csr -signkey server.key -out server.crt </code></pre><p>生成证书之后，修改harbor.yaml文件<br>具体配置如下<br><a href="http://52.83.79.244:6875/uploads/images/gallery/2019-12-Dec/WX20191219-155232@2x.png" target="_blank" rel="noopener"><img src="http://52.83.79.244:6875/uploads/images/gallery/2019-12-Dec/scaled-840-0/WX20191219-155232@2x.png" srcset="/img/loading.gif" alt="WX20191219-155232@2x.png"></a></p>]]></content>
    
    
    <categories>
      
      <category>运维</category>
      
    </categories>
    
    
    <tags>
      
      <tag>https</tag>
      
      <tag>证书</tag>
      
      <tag>harbor</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>K8s监控部署方案</title>
    <link href="/2020/01/07/K8s%E7%9B%91%E6%8E%A7%E9%83%A8%E7%BD%B2%E6%96%B9%E6%A1%88/"/>
    <url>/2020/01/07/K8s%E7%9B%91%E6%8E%A7%E9%83%A8%E7%BD%B2%E6%96%B9%E6%A1%88/</url>
    
    <content type="html"><![CDATA[<h2 id="架构"><a href="#架构" class="headerlink" title="架构"></a>架构</h2><p><img src="https://i.loli.net/2020/01/08/DVBiRAwaNsnYbgL.png" srcset="/img/loading.gif" alt="grafana"></p><h2 id="部署"><a href="#部署" class="headerlink" title="部署"></a>部署</h2><p><strong>yaml文件地址 👉🏻   <a href="https://161.189.27.8:8090/dqdev/pythogoras/tree/master/k8s-yaml/prometheus" target="_blank" rel="noopener">pythagoras</a></strong></p><h3 id="1-在k8s集群中创建namespace"><a href="#1-在k8s集群中创建namespace" class="headerlink" title="1 在k8s集群中创建namespace"></a>1 在k8s集群中创建namespace</h3><pre><code class="yaml">apiVersion: v1kind: Namespacemetadata:   name: ns-monitor  labels:    name: ns-monitorkubectl apply -f namespace.yaml</code></pre><h3 id="2-安装node-exporter"><a href="#2-安装node-exporter" class="headerlink" title="2 安装node-exporter"></a>2 安装node-exporter</h3><p>在kubernetest集群中部署node-exporter，Node-exporter用于采集kubernetes集群中各个节点的物理指标，比如：Memory、CPU等。可以直接在每个物理节点是直接安装，这里我们使用DaemonSet部署到每个节点上，使用 hostNetwork: true 和 hostPID: true 使其获得Node的物理指标信息，配置tolerations使其在master节点也启动一个pod。</p><p>node-exporter.yaml</p><pre><code class="yaml">kind: DaemonSetapiVersion: apps/v1beta2metadata:   labels:    app: node-exporter  name: node-exporter  namespace: ns-monitorspec:  revisionHistoryLimit: 10  selector:    matchLabels:      app: node-exporter  template:    metadata:      labels:        app: node-exporter    spec:      containers:        - name: node-exporter          image: prom/node-exporter:v0.16.0          ports:            - containerPort: 9100              protocol: TCP              name:    http      hostNetwork: true      hostPID: true      tolerations:        - effect: NoSchedule          operator: Exists---kind: ServiceapiVersion: v1metadata:  labels:    app: node-exporter  name: node-exporter-service  namespace: ns-monitorspec:  ports:    - name:    http      port: 9100      nodePort: 31672      protocol: TCP  type: NodePort  selector:    app: node-exporter</code></pre><pre><code class="shell">kubectl apply -f node-exporter.yaml</code></pre><p><strong>*检查是否执行成功(对应pod及svc)</strong> 👉🏻 **</p><pre><code class="shell">➜  ~ kubectl get pod -n ns-monitorNAME                          READY   STATUS    RESTARTS   AGEgrafana-547699f75-lxljq       1/1     Running   0          3h37mnode-exporter-75nmc           0/1     Pending   0          20hnode-exporter-t29kx           1/1     Running   0          20hnode-exporter-z6s7x           1/1     Running   0          20hprometheus-7d7654554d-f5fvf   1/1     Running   0          3h45m➜  ~ kubectl get svc -n ns-monitorNAME                    TYPE       CLUSTER-IP     EXTERNAL-IP   PORT(S)          AGEgrafana-service         NodePort   10.1.242.56    &lt;none&gt;        3000:31026/TCP   3h38mnode-exporter-service   NodePort   10.1.130.7     &lt;none&gt;        9100:31672/TCP   20hprometheus-service      NodePort   10.1.133.130   &lt;none&gt;        9090:30753/TCP   3h45m</code></pre><p><img src="https://i.loli.net/2020/01/08/TP6tIlvFKhgzHuZ.png" srcset="/img/loading.gif" alt="image-20200103143320329"></p><h3 id="3-部署Prometheus-pod"><a href="#3-部署Prometheus-pod" class="headerlink" title="3 部署Prometheus pod"></a>3 部署Prometheus pod</h3><p>prometheus.yaml 中包含rbac认证、ConfigMap等</p><pre><code class="shell">kubectl apply -f prometheus.yaml </code></pre><p><em>检查是否执行成功(对应pod及svc)*</em> 👉🏻 </p><pre><code class="shell">➜  ~ kubectl get pod -n ns-monitorNAME                          READY   STATUS    RESTARTS   AGEgrafana-547699f75-lxljq       1/1     Running   0          3h37mnode-exporter-75nmc           0/1     Pending   0          20hnode-exporter-t29kx           1/1     Running   0          20hnode-exporter-z6s7x           1/1     Running   0          20hprometheus-7d7654554d-f5fvf   1/1     Running   0          3h45m➜  ~ kubectl get svc -n ns-monitorNAME                    TYPE       CLUSTER-IP     EXTERNAL-IP   PORT(S)          AGEgrafana-service         NodePort   10.1.242.56    &lt;none&gt;        3000:31026/TCP   3h38mnode-exporter-service   NodePort   10.1.130.7     &lt;none&gt;        9100:31672/TCP   20hprometheus-service      NodePort   10.1.133.130   &lt;none&gt;        9090:30753/TCP   3h45m</code></pre><p><img src="https://i.loli.net/2020/01/08/fdFs8EN2xhHwCM6.png" srcset="/img/loading.gif" alt="image-20200103143645494"></p><h3 id="4-在k8s中部署grafana"><a href="#4-在k8s中部署grafana" class="headerlink" title="4 在k8s中部署grafana"></a>4 在k8s中部署grafana</h3><pre><code class="shell">kubectl apply -f grafana.yaml</code></pre><p><strong>检查是否执行成功(对应pod及svc)</strong> 👉🏻 </p><pre><code class="shell">➜  ~ kubectl get pod -n ns-monitorNAME                          READY   STATUS    RESTARTS   AGEgrafana-547699f75-lxljq       1/1     Running   0          3h37mnode-exporter-75nmc           0/1     Pending   0          20hnode-exporter-t29kx           1/1     Running   0          20hnode-exporter-z6s7x           1/1     Running   0          20hprometheus-7d7654554d-f5fvf   1/1     Running   0          3h45m➜  ~ kubectl get svc -n ns-monitorNAME                    TYPE       CLUSTER-IP     EXTERNAL-IP   PORT(S)          AGEgrafana-service         NodePort   10.1.242.56    &lt;none&gt;        3000:31026/TCP   3h38mnode-exporter-service   NodePort   10.1.130.7     &lt;none&gt;        9100:31672/TCP   20hprometheus-service      NodePort   10.1.133.130   &lt;none&gt;        9090:30753/TCP   3h45m</code></pre><h3 id="5-配置grafana数据源"><a href="#5-配置grafana数据源" class="headerlink" title="5 配置grafana数据源"></a>5 配置grafana数据源</h3><p>把prometheus配置成数据源 ：<a href="http://prometheus-service.ns-monitor:9090" target="_blank" rel="noopener">http://prometheus-service.ns-monitor:9090</a></p><p><img src="https://i.loli.net/2020/01/08/fzxnrR5iguDjlHk.png" srcset="/img/loading.gif" alt="image-20200103144416930"></p><h3 id="6-倒入dashboard"><a href="#6-倒入dashboard" class="headerlink" title="6 倒入dashboard"></a>6 倒入dashboard</h3><p>把 kubernetes的Dashboard的模板导入进来，直接把JSON格式内容复制进来。</p><p><img src="https://i.loli.net/2020/01/08/6XkA5hEjN1OWioS.png" srcset="/img/loading.gif" alt="image-20200103145516630"></p><h2 id="效果图"><a href="#效果图" class="headerlink" title="效果图"></a>效果图</h2><p><img src="https://i.loli.net/2020/01/08/bqEolIi8KVSGuHk.png" srcset="/img/loading.gif" alt="image-20200103145627198"></p><h2 id="Ref"><a href="#Ref" class="headerlink" title="Ref"></a>Ref</h2><ul><li><p><a href="https://jimmysong.io/kubernetes-handbook/practice/using-prometheus-to-monitor-kuberentes-cluster.html" target="_blank" rel="noopener">使用Prometheus监控kubernetes集群</a></p></li><li><p><a href="https://www.jianshu.com/p/ac8853927528" target="_blank" rel="noopener">k8s安装Prometheus+Grafana</a></p></li><li><p><a href="https://github.com/giantswarm/kubernetes-prometheus" target="_blank" rel="noopener">github-kubernetes-promethues</a></p></li><li><p><a href="https://github.com/giantswarm/prometheus" target="_blank" rel="noopener">github-giantswarm-promethues</a></p></li></ul>]]></content>
    
    
    <categories>
      
      <category>kubernetes</category>
      
    </categories>
    
    
    <tags>
      
      <tag>kubernetes</tag>
      
      <tag>grafana</tag>
      
      <tag>prometheus</tag>
      
      <tag>监控</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Gitlab开启Https</title>
    <link href="/2020/01/07/gitlab%E5%BC%80%E5%90%AFhttps/"/>
    <url>/2020/01/07/gitlab%E5%BC%80%E5%90%AFhttps/</url>
    
    <content type="html"><![CDATA[<h2 id="Gitlab开启Https"><a href="#Gitlab开启Https" class="headerlink" title="Gitlab开启Https"></a>Gitlab开启Https</h2><h3 id="建立认证目录"><a href="#建立认证目录" class="headerlink" title="建立认证目录"></a>建立认证目录</h3><pre><code class="shell">mkdir -p /etc/gitlab/sslchmod 700 /etc/gitlab/ssl</code></pre><h3 id="建立证书"><a href="#建立证书" class="headerlink" title="建立证书"></a>建立证书</h3><pre><code class="shell"># step 1 创建private key （记住输入的密码（Pass phrase））openssl genrsa -des3 -out /etc/gitlab/ssl/server.key 2048# step 2 生成 Certificate Requestopenssl req -new -key /etc/gitlab/ssl/gitlab.domain.com.key -out /etc/gitlab/ssl/server.csr</code></pre><blockquote><p> Enter Country Name CN<br> Enter State or Province Full Name HB<br> Enter City Name WuHan<br> Enter Organization Name<br> Enter Company Name EV-IV<br> Enter Organizational Unit Name<br> Enter server hostname i.e. URL gitlab.domain.com<br> Enter Admin Email Address<br> Skip Challenge Password (Hit Enter)<br> Skip Optional Company Name (Hit Enter)</p></blockquote><pre><code class="shell">#在加载SSL支持的Nginx并使用上述私钥时要除去刚才设置的口令： #step3 备份csr文件及去除命令，直接覆盖了server.key了openssl rsa -inserver.key.org -out server.key#step 4最后标记证书使用上述私钥和CSR：（把csr标记后转换成了crt nginx要用key和crt文件）openssl x509 -req -days 365 -in server.csr -signkey server.key -out server.crt</code></pre><h3 id="修改gitlab配置"><a href="#修改gitlab配置" class="headerlink" title="修改gitlab配置"></a>修改gitlab配置</h3><pre><code class="shell">vim /etc/gitlab/gitlab.rbexternal_url &#39;https://161.189.27.8:8090/&#39;nginx[&#39;redirect_http_to_https&#39;]= truenginx[&#39;ssl_client_certificate&#39;] = &quot;/etc/gitlab/ssl/server.crt&quot;nginx[&#39;ssl_certificate&#39;]= &quot;/etc/gitlab/ssl/server.crt&quot;nginx[&#39;ssl_certificate_key&#39;]= &quot;/etc/gitlab/ssl/server.key&quot;</code></pre><h3 id="重启gitlab"><a href="#重启gitlab" class="headerlink" title="重启gitlab"></a>重启gitlab</h3><pre><code class="shell">gitlab-ctl reconfiguregitlab-ctl restart</code></pre><p>最后通过访问https地址进行访问测试</p><h3 id="相关问题"><a href="#相关问题" class="headerlink" title="相关问题"></a>相关问题</h3><p>Q1 由于ssl证书为自签证书 git clone报错</p><pre><code class="shell">git clone https://161.189.27.8:8090/dqdev/pythogoras.gitCloning into &#39;pythogoras&#39;...fatal: unable to access &#39;https://161.189.27.8:8090/dqdev/pythogoras.git/&#39;: SSL certificate problem: self signed certificate</code></pre><p>关闭git ssl验证</p><pre><code class="bash">git config --global http.sslVerify false 关闭git config --global http.sslVerify true  开启</code></pre>]]></content>
    
    
    <categories>
      
      <category>运维</category>
      
    </categories>
    
    
    <tags>
      
      <tag>gitlab</tag>
      
      <tag>ssl</tag>
      
      <tag>https</tag>
      
      <tag>证书</tag>
      
    </tags>
    
  </entry>
  
  
  
  
</search>
